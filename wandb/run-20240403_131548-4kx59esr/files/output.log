                                                                                                                                       /home/wang4538/.conda/envs/cent7/2020.11-py38/low/lib/python3.11/site-packages/composer/loggers/wandb_logger.py:291: UserWarning: WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. The file with name '/scratch/gilbreth/wang4538/DGMS/debug/cifar10/latest:latest' will be stored as '.scratch.gilbreth.wang4538.DGMS.debug.cifar10.latest:latest'.
  warnings.warn(('WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. '
/home/wang4538/.conda/envs/cent7/2020.11-py38/low/lib/python3.11/site-packages/composer/loggers/wandb_logger.py:291: UserWarning: WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. The file with name '/scratch/gilbreth/wang4538/DGMS/debug/cifar10/latest.symlink:latest' will be stored as '.scratch.gilbreth.wang4538.DGMS.debug.cifar10.latest.symlink:latest'.
  warnings.warn(('WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. '
******************************
Config:
composer_commit_hash: None
composer_version: 0.17.2
node_name: unknown because NODENAME environment variable not set
num_gpus_per_node: 1
num_nodes: 1
rank_zero_seed: 1
******************************
train          Epoch   0:    0%|                         | 0/195 [00:00<?, ?ba/s]
Epoch: 0ep
Try to print Module Name
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv



[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 21. Dropping entry: {'time/epoch': 0, '_timestamp': 1712164556.8529327}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 21. Dropping entry: {'time/batch': 0, 'time/sample': 0, 'time/batch_in_epoch': 0, 'time/sample_in_epoch': 0, '_timestamp': 1712164557.1813726}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164560.0394256}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8863372802734375, '_timestamp': 1712164560.0467427}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 0 is less than current step: 21. Dropping entry: {'_timestamp': 1712164560.0496287}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 21. Dropping entry: {'time/batch': 1, 'time/sample': 256, 'time/batch_in_epoch': 1, 'time/sample_in_epoch': 256, '_timestamp': 1712164560.0519626}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164561.6250331}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 21. Dropping entry: {'loss/train/total': 7.9986572265625, '_timestamp': 1712164561.6275103}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 1 is less than current step: 21. Dropping entry: {'_timestamp': 1712164561.6302571}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 21. Dropping entry: {'time/batch': 2, 'time/sample': 512, 'time/batch_in_epoch': 2, 'time/sample_in_epoch': 512, '_timestamp': 1712164561.631699}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164563.438269}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 21. Dropping entry: {'loss/train/total': 7.953826904296875, '_timestamp': 1712164563.4407604}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 2 is less than current step: 21. Dropping entry: {'_timestamp': 1712164563.4436011}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 21. Dropping entry: {'time/batch': 3, 'time/sample': 768, 'time/batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164563.445157}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164564.2605276}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 21. Dropping entry: {'loss/train/total': 8.077285766601562, '_timestamp': 1712164564.260884}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 3 is less than current step: 21. Dropping entry: {'_timestamp': 1712164564.2617717}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 21. Dropping entry: {'time/batch': 4, 'time/sample': 1024, 'time/batch_in_epoch': 4, 'time/sample_in_epoch': 1024, '_timestamp': 1712164564.2630603}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164564.712913}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 21. Dropping entry: {'loss/train/total': 7.9496917724609375, '_timestamp': 1712164564.713425}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 4 is less than current step: 21. Dropping entry: {'_timestamp': 1712164564.7146347}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 21. Dropping entry: {'time/batch': 5, 'time/sample': 1280, 'time/batch_in_epoch': 5, 'time/sample_in_epoch': 1280, '_timestamp': 1712164564.7158937}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164565.16869}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 21. Dropping entry: {'loss/train/total': 7.84039306640625, '_timestamp': 1712164565.1690793}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 5 is less than current step: 21. Dropping entry: {'_timestamp': 1712164565.1700585}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 21. Dropping entry: {'time/batch': 6, 'time/sample': 1536, 'time/batch_in_epoch': 6, 'time/sample_in_epoch': 1536, '_timestamp': 1712164565.1713936}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164565.6571426}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 21. Dropping entry: {'loss/train/total': 7.9954833984375, '_timestamp': 1712164565.6574268}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 6 is less than current step: 21. Dropping entry: {'_timestamp': 1712164565.658217}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 21. Dropping entry: {'time/batch': 7, 'time/sample': 1792, 'time/batch_in_epoch': 7, 'time/sample_in_epoch': 1792, '_timestamp': 1712164565.6593459}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164566.0686898}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 21. Dropping entry: {'loss/train/total': 7.9148406982421875, '_timestamp': 1712164566.0690656}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 7 is less than current step: 21. Dropping entry: {'_timestamp': 1712164566.070014}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 21. Dropping entry: {'time/batch': 8, 'time/sample': 2048, 'time/batch_in_epoch': 8, 'time/sample_in_epoch': 2048, '_timestamp': 1712164566.0713422}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164566.5556445}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8820037841796875, '_timestamp': 1712164566.5560281}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 8 is less than current step: 21. Dropping entry: {'_timestamp': 1712164566.5568993}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 9 is less than current step: 21. Dropping entry: {'time/batch': 9, 'time/sample': 2304, 'time/batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164566.5580065}).







[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 9 is less than current step: 21. Dropping entry: {'loss/train/total': 8.031326293945312, '_timestamp': 1712164567.0045211}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 9 is less than current step: 21. Dropping entry: {'_timestamp': 1712164567.005668}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 21. Dropping entry: {'time/batch': 10, 'time/sample': 2560, 'time/batch_in_epoch': 10, 'time/sample_in_epoch': 2560, '_timestamp': 1712164567.0069487}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164567.4660277}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 21. Dropping entry: {'loss/train/total': 7.7729949951171875, '_timestamp': 1712164567.4663713}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 10 is less than current step: 21. Dropping entry: {'_timestamp': 1712164567.4672954}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 21. Dropping entry: {'time/batch': 11, 'time/sample': 2816, 'time/batch_in_epoch': 11, 'time/sample_in_epoch': 2816, '_timestamp': 1712164567.4687772}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164567.8821895}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 21. Dropping entry: {'loss/train/total': 7.919281005859375, '_timestamp': 1712164567.8825877}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 11 is less than current step: 21. Dropping entry: {'_timestamp': 1712164567.8837123}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 21. Dropping entry: {'time/batch': 12, 'time/sample': 3072, 'time/batch_in_epoch': 12, 'time/sample_in_epoch': 3072, '_timestamp': 1712164567.8849342}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164568.3598237}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 21. Dropping entry: {'loss/train/total': 7.7721710205078125, '_timestamp': 1712164568.3600664}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 12 is less than current step: 21. Dropping entry: {'_timestamp': 1712164568.3608081}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 21. Dropping entry: {'time/batch': 13, 'time/sample': 3328, 'time/batch_in_epoch': 13, 'time/sample_in_epoch': 3328, '_timestamp': 1712164568.361933}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164568.8425984}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 21. Dropping entry: {'loss/train/total': 7.834197998046875, '_timestamp': 1712164568.843152}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 13 is less than current step: 21. Dropping entry: {'_timestamp': 1712164568.8443415}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 21. Dropping entry: {'time/batch': 14, 'time/sample': 3584, 'time/batch_in_epoch': 14, 'time/sample_in_epoch': 3584, '_timestamp': 1712164568.8454876}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164569.2687004}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8739013671875, '_timestamp': 1712164569.2690046}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 14 is less than current step: 21. Dropping entry: {'_timestamp': 1712164569.2698474}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 21. Dropping entry: {'time/batch': 15, 'time/sample': 3840, 'time/batch_in_epoch': 15, 'time/sample_in_epoch': 3840, '_timestamp': 1712164569.2709584}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164569.7574196}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8668670654296875, '_timestamp': 1712164569.757813}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 15 is less than current step: 21. Dropping entry: {'_timestamp': 1712164569.7588766}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 21. Dropping entry: {'time/batch': 16, 'time/sample': 4096, 'time/batch_in_epoch': 16, 'time/sample_in_epoch': 4096, '_timestamp': 1712164569.7600634}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164570.1770563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8658294677734375, '_timestamp': 1712164570.1776032}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 16 is less than current step: 21. Dropping entry: {'_timestamp': 1712164570.1784213}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 21. Dropping entry: {'time/batch': 17, 'time/sample': 4352, 'time/batch_in_epoch': 17, 'time/sample_in_epoch': 4352, '_timestamp': 1712164570.1795123}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164570.6645448}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 21. Dropping entry: {'loss/train/total': 7.951751708984375, '_timestamp': 1712164570.664934}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 17 is less than current step: 21. Dropping entry: {'_timestamp': 1712164570.665806}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 21. Dropping entry: {'time/batch': 18, 'time/sample': 4608, 'time/batch_in_epoch': 18, 'time/sample_in_epoch': 4608, '_timestamp': 1712164570.6669772}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164571.1561625}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8642425537109375, '_timestamp': 1712164571.156447}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 18 is less than current step: 21. Dropping entry: {'_timestamp': 1712164571.1572623}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 21. Dropping entry: {'time/batch': 19, 'time/sample': 4864, 'time/batch_in_epoch': 19, 'time/sample_in_epoch': 4864, '_timestamp': 1712164571.158323}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164571.5772753}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 21. Dropping entry: {'loss/train/total': 7.8427886962890625, '_timestamp': 1712164571.5775714}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 19 is less than current step: 21. Dropping entry: {'_timestamp': 1712164571.5783966}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 21. Dropping entry: {'time/batch': 20, 'time/sample': 5120, 'time/batch_in_epoch': 20, 'time/sample_in_epoch': 5120, '_timestamp': 1712164571.5795033}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 21. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712164572.0618107}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 21. Dropping entry: {'loss/train/total': 7.9028167724609375, '_timestamp': 1712164572.0620503}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 20 is less than current step: 21. Dropping entry: {'_timestamp': 1712164572.0628004}).
train          Epoch   0:   15%|â–ˆâ–ˆâ–ˆâ–‹                     | 29/195 [00:29<06:23,  2.31s/ba, loss/train/total=7.8994]
train          Epoch   0:   15%|â–ˆâ–ˆâ–ˆâ–Š                     | 30/195 [00:32<06:46,  2.47s/ba, loss/train/total=7.9633]
train          Epoch   0:   16%|â–ˆâ–ˆâ–ˆâ–‰                     | 31/195 [00:35<06:55,  2.53s/ba, loss/train/total=7.7884]
train          Epoch   0:   17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    | 33/195 [00:38<05:18,  1.96s/ba, loss/train/total=7.8904]
train          Epoch   0:   18%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    | 35/195 [00:40<03:45,  1.41s/ba, loss/train/total=7.8865]
train          Epoch   0:   19%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 37/195 [00:42<03:00,  1.14s/ba, loss/train/total=7.7293]
train          Epoch   0:   21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 40/195 [00:44<02:32,  1.02ba/s, loss/train/total=7.8204]
train          Epoch   0:   22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 42/195 [00:46<02:28,  1.03ba/s, loss/train/total=7.8077]
train          Epoch   0:   23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 45/195 [00:48<01:44,  1.43ba/s, loss/train/total=7.6260]
train          Epoch   0:   26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 50/195 [00:50<01:11,  2.03ba/s, loss/train/total=7.6282]
train          Epoch   0:   26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 51/195 [00:52<01:54,  1.25ba/s, loss/train/total=7.5562]
train          Epoch   0:   27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 52/195 [00:54<02:36,  1.10s/ba, loss/train/total=7.5761]
train          Epoch   0:   27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 53/195 [00:55<03:05,  1.31s/ba, loss/train/total=7.4494]
train          Epoch   0:   28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 54/195 [00:57<03:26,  1.46s/ba, loss/train/total=7.6008]
train          Epoch   0:   28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 55/195 [00:59<03:40,  1.57s/ba, loss/train/total=7.7485]
train          Epoch   0:   29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 56/195 [01:01<03:46,  1.63s/ba, loss/train/total=7.6258]
train          Epoch   0:   31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 61/195 [01:04<01:40,  1.33ba/s, loss/train/total=7.6406]
train          Epoch   0:   33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 65/195 [01:06<01:10,  1.85ba/s, loss/train/total=7.4260]
train          Epoch   0:   34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 67/195 [01:08<01:48,  1.18ba/s, loss/train/total=7.5872]
train          Epoch   0:   35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 69/195 [01:10<01:51,  1.13ba/s, loss/train/total=7.4066]
train          Epoch   0:   36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 71/195 [01:12<01:54,  1.08ba/s, loss/train/total=7.4899]
train          Epoch   0:   37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 73/195 [01:14<01:50,  1.10ba/s, loss/train/total=7.4322]
train          Epoch   0:   38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 75/195 [01:16<01:48,  1.10ba/s, loss/train/total=7.6695]
train          Epoch   0:   39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 77/195 [01:17<01:46,  1.11ba/s, loss/train/total=7.5010]
train          Epoch   0:   40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 78/195 [01:18<01:46,  1.10ba/s, loss/train/total=7.3496]
train          Epoch   0:   41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 79/195 [01:21<02:47,  1.45s/ba, loss/train/total=7.3365]
train          Epoch   0:   41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 80/195 [01:24<03:31,  1.83s/ba, loss/train/total=7.3284]
train          Epoch   0:   42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 81/195 [01:27<04:07,  2.17s/ba, loss/train/total=7.3669]
train          Epoch   0:   42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 82/195 [01:29<04:16,  2.27s/ba, loss/train/total=7.4930]
train          Epoch   0:   43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 83/195 [01:32<04:32,  2.43s/ba, loss/train/total=7.4301]
train          Epoch   0:   43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 84/195 [01:35<04:36,  2.49s/ba, loss/train/total=7.2732]
train          Epoch   0:   44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 86/195 [01:38<03:37,  2.00s/ba, loss/train/total=7.2981]
train          Epoch   0:   47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 91/195 [01:40<01:12,  1.43ba/s, loss/train/total=7.4167]
train          Epoch   0:   49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 96/195 [01:42<00:46,  2.13ba/s, loss/train/total=7.4005]
train          Epoch   0:   51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 100/195 [01:44<00:41,  2.28ba/s, loss/train/total=7.4686]
train          Epoch   0:   54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 105/195 [01:46<00:39,  2.27ba/s, loss/train/total=7.2274]
train          Epoch   0:   56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 109/195 [01:48<00:37,  2.31ba/s, loss/train/total=7.3189]
train          Epoch   0:   57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 111/195 [01:50<01:03,  1.32ba/s, loss/train/total=7.1955]
train          Epoch   0:   57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 112/195 [01:52<01:40,  1.21s/ba, loss/train/total=7.3535]
train          Epoch   0:   58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 113/195 [01:55<02:11,  1.60s/ba, loss/train/total=7.1550]
train          Epoch   0:   58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 114/195 [01:58<02:36,  1.93s/ba, loss/train/total=7.1351]
train          Epoch   0:   59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 115/195 [02:00<02:53,  2.17s/ba, loss/train/total=7.1787]
train          Epoch   0:   59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 116/195 [02:02<02:51,  2.17s/ba, loss/train/total=7.3273]
train          Epoch   0:   60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 117/195 [02:05<03:04,  2.37s/ba, loss/train/total=7.3255]
train          Epoch   0:   61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 119/195 [02:08<02:12,  1.75s/ba, loss/train/total=7.2103]
train          Epoch   0:   63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 122/195 [02:10<01:28,  1.21s/ba, loss/train/total=7.1698]
train          Epoch   0:   64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 124/195 [02:12<01:04,  1.10ba/s, loss/train/total=7.2407]
train          Epoch   0:   65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 127/195 [02:14<00:55,  1.23ba/s, loss/train/total=7.0761]
train          Epoch   0:   66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 129/195 [02:16<01:01,  1.06ba/s, loss/train/total=7.0511]
train          Epoch   0:   67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 131/195 [02:18<00:58,  1.09ba/s, loss/train/total=7.2221]
train          Epoch   0:   68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 133/195 [02:20<00:47,  1.30ba/s, loss/train/total=7.1129]
train          Epoch   0:   69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 135/195 [02:22<00:54,  1.09ba/s, loss/train/total=7.1421]
train          Epoch   0:   71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 139/195 [02:24<00:33,  1.68ba/s, loss/train/total=7.1147]
train          Epoch   0:   72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 141/195 [02:26<00:54,  1.00s/ba, loss/train/total=6.9683]
train          Epoch   0:   73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 142/195 [02:28<01:00,  1.14s/ba, loss/train/total=7.0348]
train          Epoch   0:   73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 143/195 [02:29<01:03,  1.23s/ba, loss/train/total=6.9098]
train          Epoch   0:   74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 144/195 [02:31<01:11,  1.40s/ba, loss/train/total=6.8646]
train          Epoch   0:   74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 145/195 [02:33<01:16,  1.53s/ba, loss/train/total=6.9351]
train          Epoch   0:   75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 146/195 [02:35<01:18,  1.61s/ba, loss/train/total=7.0346]
train          Epoch   0:   77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 151/195 [02:38<00:31,  1.38ba/s, loss/train/total=7.0373]
train          Epoch   0:   80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 156/195 [02:40<00:18,  2.11ba/s, loss/train/total=6.9627]
train          Epoch   0:   82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 159/195 [02:42<00:16,  2.24ba/s, loss/train/total=6.8206]
train          Epoch   0:   83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 162/195 [02:44<00:23,  1.39ba/s, loss/train/total=6.8480]
train          Epoch   0:   84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 164/195 [02:46<00:25,  1.21ba/s, loss/train/total=6.9547]
train          Epoch   0:   86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 167/195 [02:49<00:24,  1.13ba/s, loss/train/total=6.9349]
train          Epoch   0:   87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 169/195 [02:50<00:19,  1.33ba/s, loss/train/total=6.9859]
train          Epoch   0:   88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 172/195 [02:52<00:17,  1.31ba/s, loss/train/total=6.9709]
train          Epoch   0:   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 173/195 [02:54<00:20,  1.09ba/s, loss/train/total=6.8846]
train          Epoch   0:   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 174/195 [02:56<00:30,  1.44s/ba, loss/train/total=6.8654]
train          Epoch   0:   90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 175/195 [02:59<00:36,  1.82s/ba, loss/train/total=6.9721]
train          Epoch   0:   90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 176/195 [03:02<00:40,  2.14s/ba, loss/train/total=6.9581]
train          Epoch   0:   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 177/195 [03:04<00:40,  2.23s/ba, loss/train/total=7.0946]
train          Epoch   0:   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 178/195 [03:07<00:38,  2.27s/ba, loss/train/total=6.8177]
train          Epoch   0:   92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 179/195 [03:10<00:39,  2.47s/ba, loss/train/total=6.9846]
train          Epoch   0:   92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 180/195 [03:12<00:38,  2.57s/ba, loss/train/total=6.9628]
train          Epoch   0:   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 183/195 [03:14<00:15,  1.25s/ba, loss/train/total=6.8862]
train          Epoch   0:   96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 187/195 [03:16<00:05,  1.54ba/s, loss/train/total=6.8794]
train          Epoch   0:   98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/195 [03:18<00:01,  2.02ba/s, loss/train/total=6.8919]
train          Epoch   0:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [03:20<00:00,  2.10ba/s, loss/train/total=6.8618]
train          Epoch   0:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [03:20<00:00,  2.10ba/s, loss/train/total=6.8618]
Epoch: 1ep
Try to print Module Name
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
Found DGMSConv
train          Epoch   1:    1%|â–Ž                        | 2/195 [00:02<03:30,  1.09s/ba, loss/train/total=6.8437]
train          Epoch   1:    2%|â–                        | 3/195 [00:04<04:51,  1.52s/ba, loss/train/total=6.8453]
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 216. Dropping entry: {'time/batch': 198, 'time/sample': 50688, 'time/batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    2%|â–Œ                        | 4/195 [00:07<06:31,  2.05s/ba, loss/train/total=6.8750]                      batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    3%|â–‹                        | 5/195 [00:09<07:01,  2.22s/ba, loss/train/total=6.8091]                      batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    3%|â–Š                        | 6/195 [00:12<07:33,  2.40s/ba, loss/train/total=6.8665]                      batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    4%|â–‰                        | 7/195 [00:14<07:48,  2.49s/ba, loss/train/total=6.8250]                      batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    4%|â–ˆ                        | 8/195 [00:17<08:10,  2.62s/ba, loss/train/total=6.9082]                      batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712164761.678773})..
train          Epoch   1:    5%|â–ˆâ–Ž                       | 10/195 [00:20<05:36,  1.82s/ba, loss/train/total=6.9591]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:    6%|â–ˆâ–Œ                       | 12/195 [00:21<03:58,  1.30s/ba, loss/train/total=6.8833]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:    7%|â–ˆâ–Š                       | 14/195 [00:23<03:20,  1.11s/ba, loss/train/total=6.7732]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:    9%|â–ˆâ–ˆâ–                      | 17/195 [00:26<02:52,  1.03ba/s, loss/train/total=6.8067]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:   10%|â–ˆâ–ˆâ–                      | 19/195 [00:28<02:50,  1.03ba/s, loss/train/total=6.7609]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:   11%|â–ˆâ–ˆâ–‹                      | 21/195 [00:29<02:21,  1.23ba/s, loss/train/total=6.7289]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:   12%|â–ˆâ–ˆâ–ˆ                      | 24/195 [00:32<02:14,  1.27ba/s, loss/train/total=6.6998]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
train          Epoch   1:   13%|â–ˆâ–ˆâ–ˆâ–Ž                     | 26/195 [00:34<02:34,  1.10ba/s, loss/train/total=6.8110]                     batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712164776.765819})..
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 216. Dropping entry: {'loss/train/total': 6.7288970947265625, '_timestamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 95/195 [01:37<01:32,  1.08ba/s, loss/train/total=6.6321]                     tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 96/195 [01:39<01:57,  1.18s/ba, loss/train/total=6.7597]                     tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 97/195 [01:42<02:35,  1.58s/ba, loss/train/total=6.7332]                     tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 98/195 [01:44<02:58,  1.84s/ba, loss/train/total=6.7430]                     tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 99/195 [01:47<03:19,  2.08s/ba, loss/train/total=6.6855]                     tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 100/195 [01:50<03:38,  2.30s/ba, loss/train/total=6.6702]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 101/195 [01:52<03:31,  2.25s/ba, loss/train/total=6.8472]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 103/195 [01:54<02:23,  1.56s/ba, loss/train/total=6.6742]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 105/195 [01:55<01:50,  1.23s/ba, loss/train/total=6.7357]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 108/195 [01:58<01:29,  1.02s/ba, loss/train/total=6.6487]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 110/195 [01:59<01:10,  1.21ba/s, loss/train/total=6.6659]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 113/195 [02:02<01:05,  1.25ba/s, loss/train/total=6.6326]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 114/195 [02:03<01:15,  1.07ba/s, loss/train/total=6.7636]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 117/195 [02:06<01:11,  1.09ba/s, loss/train/total=6.6541]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 119/195 [02:07<00:58,  1.31ba/s, loss/train/total=6.6698]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 122/195 [02:10<00:57,  1.26ba/s, loss/train/total=6.6271]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 126/195 [02:11<00:34,  1.98ba/s, loss/train/total=6.7060]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 128/195 [02:14<01:02,  1.08ba/s, loss/train/total=6.6988]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 129/195 [02:15<01:14,  1.12s/ba, loss/train/total=6.7648]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 130/195 [02:17<01:25,  1.32s/ba, loss/train/total=6.6772]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 131/195 [02:19<01:31,  1.43s/ba, loss/train/total=6.6391]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 133/195 [02:22<01:26,  1.39s/ba, loss/train/total=6.6054]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 134/195 [02:23<01:23,  1.36s/ba, loss/train/total=6.8367]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 139/195 [02:26<00:35,  1.56ba/s, loss/train/total=6.6526]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 143/195 [02:28<00:25,  2.03ba/s, loss/train/total=6.6184]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 147/195 [02:30<00:28,  1.71ba/s, loss/train/total=6.6845]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 149/195 [02:32<00:34,  1.35ba/s, loss/train/total=6.7577]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 151/195 [02:33<00:36,  1.21ba/s, loss/train/total=6.6950]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 153/195 [02:35<00:30,  1.39ba/s, loss/train/total=6.6546]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 156/195 [02:37<00:29,  1.33ba/s, loss/train/total=6.5923]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 159/195 [02:40<00:27,  1.31ba/s, loss/train/total=6.6812]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 160/195 [02:41<00:32,  1.09ba/s, loss/train/total=6.7299]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 161/195 [02:43<00:37,  1.10s/ba, loss/train/total=6.6176]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 162/195 [02:45<00:50,  1.52s/ba, loss/train/total=6.6463]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 163/195 [02:48<00:59,  1.86s/ba, loss/train/total=6.6335]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 164/195 [02:51<01:06,  2.14s/ba, loss/train/total=6.7691]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 165/195 [02:54<01:11,  2.39s/ba, loss/train/total=6.6416]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 166/195 [02:56<01:11,  2.48s/ba, loss/train/total=6.6362]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 167/195 [02:59<01:10,  2.53s/ba, loss/train/total=6.7386]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 169/195 [03:01<00:46,  1.80s/ba, loss/train/total=6.7210]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 174/195 [03:04<00:14,  1.44ba/s, loss/train/total=6.6749]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 178/195 [03:06<00:08,  1.98ba/s, loss/train/total=6.5886]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 183/195 [03:08<00:05,  2.20ba/s, loss/train/total=6.7407]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 187/195 [03:10<00:03,  2.18ba/s, loss/train/total=6.6382]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/195 [03:12<00:04,  1.39ba/s, loss/train/total=6.6673]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 190/195 [03:13<00:05,  1.05s/ba, loss/train/total=6.6304]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 191/195 [03:16<00:06,  1.53s/ba, loss/train/total=6.6529]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/195 [03:19<00:05,  1.90s/ba, loss/train/total=6.6967]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/195 [03:21<00:04,  2.07s/ba, loss/train/total=6.7719]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:   99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 194/195 [03:24<00:02,  2.17s/ba, loss/train/total=6.6866]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
train          Epoch   1:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [03:26<00:00,  2.34s/ba, loss/train/total=6.6827]                    tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:   25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 10/40 [00:03<00:07,  3.89ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:   42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 17/40 [00:05<00:05,  4.18ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:   62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 25/40 [00:07<00:03,  3.78ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:   80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/40 [00:09<00:01,  4.58ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
  warnings.warn(f'Cannot split tensor of length {len(t)} into batches of size {microbatch_size}. '                                      tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.40ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).
eval           Epoch   1:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.40ba/s]                                               tamp': 1712164787.0729713}).ample_in_epoch': 5120, '_timestamp': 1712164786.5683408}).