                                                                                                                                       /home/wang4538/.conda/envs/cent7/2020.11-py38/low/lib/python3.11/site-packages/composer/loggers/wandb_logger.py:291: UserWarning: WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. The file with name '/scratch/gilbreth/wang4538/DGMS/debug/cifar10/latest:latest' will be stored as '.scratch.gilbreth.wang4538.DGMS.debug.cifar10.latest:latest'.
  warnings.warn(('WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. '
/home/wang4538/.conda/envs/cent7/2020.11-py38/low/lib/python3.11/site-packages/composer/loggers/wandb_logger.py:291: UserWarning: WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. The file with name '/scratch/gilbreth/wang4538/DGMS/debug/cifar10/latest.symlink:latest' will be stored as '.scratch.gilbreth.wang4538.DGMS.debug.cifar10.latest.symlink:latest'.
  warnings.warn(('WandB permits only alpha-numeric, periods, hyphens, and underscores in file names. '
******************************
Config:
composer_commit_hash: None
composer_version: 0.17.2
node_name: unknown because NODENAME environment variable not set
num_gpus_per_node: 1
num_nodes: 1
rank_zero_seed: 1
******************************






train          Epoch   0:   99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/195 [00:12<00:00, 21.50ba/s, loss/train/total=0.0030]
train          Epoch   0:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [00:12<00:00, 21.50ba/s, loss/train/total=0.0041]                    /home/wang4538/.conda/envs/cent7/2020.11-py38/low/lib/python3.11/site-packages/composer/core/data_spec.py:35: UserWarning: Cannot split tensor of length 16 into batches of size 256. As it is smaller, no splitting will be done. This may happen on the last batch of a dataset if it is a smaller size than the microbatch size.
  warnings.warn(f'Cannot split tensor of length {len(t)} into batches of size {microbatch_size}. '
eval           Epoch   0:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 31.00ba/s, metrics/eval/MulticlassAccuracy=0.9487]





[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'metrics/eval/MulticlassAccuracy': 0.9487000107765198, '_timestamp': 1712283570.147976}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'time/epoch': 1, '_timestamp': 1712283570.2443671}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'time/batch': 195, 'time/sample': 49920, 'time/batch_in_epoch': 0, 'time/sample_in_epoch': 0, '_timestamp': 1712283570.4589102}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283570.6365948}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0029571191407740116, '_timestamp': 1712283570.6369119}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 195 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283570.6396549}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.1120000000000002e-05, '_timestamp': 1712283570.6403756}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 276. Dropping entry: {'time/batch': 196, 'time/sample': 50176, 'time/batch_in_epoch': 1, 'time/sample_in_epoch': 256, '_timestamp': 1712283570.6414847}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283570.7373784}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0025450726971030235, '_timestamp': 1712283570.7375784}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 196 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283570.7390132}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.1063076923076923e-05, '_timestamp': 1712283570.7395382}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 276. Dropping entry: {'time/batch': 197, 'time/sample': 50432, 'time/batch_in_epoch': 2, 'time/sample_in_epoch': 512, '_timestamp': 1712283570.74017}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283570.835799}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0024957465939223766, '_timestamp': 1712283570.8360617}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 197 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283570.8375137}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.1006153846153849e-05, '_timestamp': 1712283570.8380682}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 276. Dropping entry: {'time/batch': 198, 'time/sample': 50688, 'time/batch_in_epoch': 3, 'time/sample_in_epoch': 768, '_timestamp': 1712283570.8390553}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283570.8725517}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0040637594647705555, '_timestamp': 1712283570.8727553}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 198 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283570.8741417}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.094923076923077e-05, '_timestamp': 1712283570.8746421}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 276. Dropping entry: {'time/batch': 199, 'time/sample': 50944, 'time/batch_in_epoch': 4, 'time/sample_in_epoch': 1024, '_timestamp': 1712283570.875291}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283570.9578028}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002929891459643841, '_timestamp': 1712283570.9580114}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 199 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283570.9599142}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0892307692307693e-05, '_timestamp': 1712283570.960413}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0019637129735201597, 'l2_norm/param/network.bn1.weight': 1.1158196926116943, 'l2_norm/update/network.bn1.weight': 0.00030513523961417377, 'l2_norm/grad/network.bn1.weight': 0.007042338140308857, 'l2_norm/moment/network.bn1.bias': 0.0015663881786167622, 'l2_norm/param/network.bn1.bias': 0.9451621770858765, 'l2_norm/update/network.bn1.bias': 0.00025630282470956445, 'l2_norm/grad/network.bn1.bias': 0.004301370587199926, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.0015787099255248904, 'l2_norm/param/network.layer1.0.bn1.weight': 1.1543899774551392, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00031216282513923943, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.0047494941391050816, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.000995545880869031, 'l2_norm/param/network.layer1.0.bn1.bias': 0.691827118396759, 'l2_norm/update/network.layer1.0.bn1.bias': 0.00019284184963908046, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.003482014872133732, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.0019312280928716063, 'l2_norm/param/network.layer1.0.bn2.weight': 1.407669186592102, 'l2_norm/update/network.layer1.0.bn2.weight': 0.00038292224053293467, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.0048877038061618805, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0011332064168527722, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7228500247001648, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00019965175306424499, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.003727802773937583, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.001715840888209641, 'l2_norm/param/network.layer1.1.bn1.weight': 1.416083812713623, 'l2_norm/update/network.layer1.1.bn1.weight': 0.0003860640281345695, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.005620877258479595, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0014179546851664782, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6129248738288879, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00016732196672819555, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.003925643861293793, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.002313760807737708, 'l2_norm/param/network.layer1.1.bn2.weight': 1.32585871219635, 'l2_norm/update/network.layer1.1.bn2.weight': 0.00036033234209753573, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.007151329889893532, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.001143740606494248, 'l2_norm/param/network.layer1.1.bn2.bias': 0.9060888886451721, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00024738835054449737, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.003367406316101551, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.002550594275817275, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6400219202041626, 'l2_norm/update/network.layer2.0.bn1.weight': 0.0004473318695090711, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.007582151331007481, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0018347310833632946, 'l2_norm/param/network.layer2.0.bn1.bias': 0.755888044834137, 'l2_norm/update/network.layer2.0.bn1.bias': 0.0002080018020933494, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.005370528437197208, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.0026580868288874626, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9391677379608154, 'l2_norm/update/network.layer2.0.bn2.weight': 0.0005274250288493931, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.009986946359276772, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.0013831014512106776, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6688981056213379, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00018338377412874252, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.0069081904366612434, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.0022813312243670225, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.4186389446258545, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.0003870668588206172, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.009440968744456768, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.0013831014512106776, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6688981056213379, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00018338377412874252, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.0069081904366612434, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.003366379765793681, 'l2_norm/param/network.layer2.1.bn1.weight': 1.6098353862762451, 'l2_norm/update/network.layer2.1.bn1.weight': 0.00043903221376240253, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.011872392147779465, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.0018864499870687723, 'l2_norm/param/network.layer2.1.bn1.bias': 1.406435251235962, 'l2_norm/update/network.layer2.1.bn1.bias': 0.0003830141213256866, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.006644377019256353, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.002283047419041395, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4799704551696777, 'l2_norm/update/network.layer2.1.bn2.weight': 0.00040448567597195506, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.008312552236020565, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0014638237189501524, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9187960028648376, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00025163753889501095, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.005131079349666834, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.0037469344679266214, 'l2_norm/param/network.layer3.0.bn1.weight': 2.2559127807617188, 'l2_norm/update/network.layer3.0.bn1.weight': 0.0006161603378131986, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.014101026579737663, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.0023645274341106415, 'l2_norm/param/network.layer3.0.bn1.bias': 1.3276870250701904, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00035935468622483313, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.007830100134015083, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.005435436964035034, 'l2_norm/param/network.layer3.0.bn2.weight': 2.54744029045105, 'l2_norm/update/network.layer3.0.bn2.weight': 0.000693255104124546, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.022930102422833443, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.0028353072702884674, 'l2_norm/param/network.layer3.0.bn2.bias': 1.4013164043426514, 'l2_norm/update/network.layer3.0.bn2.bias': 0.0003828893241006881, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.009547621943056583, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.0035505732521414757, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9300568699836731, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00025274063227698207, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.011244352906942368, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.0028353072702884674, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.4013164043426514, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.0003828893241006881, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.009547621943056583, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.005815520416945219, 'l2_norm/param/network.layer3.1.bn1.weight': 2.177462577819824, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0005946470191702247, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.018346207216382027, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.0033384289126843214, 'l2_norm/param/network.layer3.1.bn1.bias': 2.078735828399658, 'l2_norm/update/network.layer3.1.bn1.bias': 0.0005667172372341156, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.009858370758593082, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0028270608745515347, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9834967851638794, 'l2_norm/update/network.layer3.1.bn2.weight': 0.0005462987464852631, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.008060520514845848, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.0018789872992783785, 'l2_norm/param/network.layer3.1.bn2.bias': 1.638020634651184, 'l2_norm/update/network.layer3.1.bn2.bias': 0.00044727924978360534, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.0053373039700090885, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0026359669864177704, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4530045986175537, 'l2_norm/update/network.layer4.0.bn1.weight': 0.00040208478458225727, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.008658971637487411, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.0020105831790715456, 'l2_norm/param/network.layer4.0.bn1.bias': 1.0024367570877075, 'l2_norm/update/network.layer4.0.bn1.bias': 0.0002733481233008206, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.0066925277933478355, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0015582907944917679, 'l2_norm/param/network.layer4.0.bn2.weight': 3.958277702331543, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0012494288384914398, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.0017865863628685474, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.000877782644238323, 'l2_norm/param/network.layer4.0.bn2.bias': 0.6534243822097778, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00023253516701515764, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0016728822374716401, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.000587426358833909, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.9260534048080444, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.0006031652446836233, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0010196102084591985, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.000877782644238323, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.6534243822097778, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00023253516701515764, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0016728822374716401, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.001243174308910966, 'l2_norm/param/network.layer4.1.bn1.weight': 0.9020333886146545, 'l2_norm/update/network.layer4.1.bn1.weight': 0.0002707319217734039, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.0031003239564597607, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.001640803413465619, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17351393401622772, 'l2_norm/update/network.layer4.1.bn1.bias': 6.744487473042682e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.0040208022110164165, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.002509544836357236, 'l2_norm/param/network.layer4.1.bn2.weight': 3.146686315536499, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0010643365094438195, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.002966676838696003, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0010085952235385776, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8912443518638611, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0003321169933769852, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.0015666061080992222, 'l2_norm/moment/network.fc.weight': 0.003362836316227913, 'l2_norm/param/network.fc.weight': 5.732325553894043, 'l2_norm/update/network.fc.weight': 0.001858578179962933, 'l2_norm/grad/network.fc.weight': 0.004906867165118456, 'l2_norm/moment/network.fc.bias': 0.0003021667944267392, 'l2_norm/param/network.fc.bias': 0.09906996786594391, 'l2_norm/update/network.fc.bias': 2.7796209906227887e-05, 'l2_norm/grad/network.fc.bias': 0.0007178591331467032, 'l2_norm/grad/global': 0.052099600434303284, '_timestamp': 1712283570.9688857}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'time/batch': 200, 'time/sample': 51200, 'time/batch_in_epoch': 5, 'time/sample_in_epoch': 1280, '_timestamp': 1712283570.9707353}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.0467293}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0029658935964107513, '_timestamp': 1712283571.0469508}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 200 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.0483007}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0835384615384616e-05, '_timestamp': 1712283571.0487962}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 276. Dropping entry: {'time/batch': 201, 'time/sample': 51456, 'time/batch_in_epoch': 6, 'time/sample_in_epoch': 1536, '_timestamp': 1712283571.0494874}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.0828085}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0026379921473562717, '_timestamp': 1712283571.083013}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 201 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.0843613}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0778461538461538e-05, '_timestamp': 1712283571.0848682}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 276. Dropping entry: {'time/batch': 202, 'time/sample': 51712, 'time/batch_in_epoch': 7, 'time/sample_in_epoch': 1792, '_timestamp': 1712283571.0857964}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.150267}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0036265156231820583, '_timestamp': 1712283571.1504664}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 202 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.1518254}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0721538461538462e-05, '_timestamp': 1712283571.1523418}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 276. Dropping entry: {'time/batch': 203, 'time/sample': 51968, 'time/batch_in_epoch': 8, 'time/sample_in_epoch': 2048, '_timestamp': 1712283571.1530125}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.1855564}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0029933638870716095, '_timestamp': 1712283571.1857703}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 203 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.232579}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0664615384615385e-05, '_timestamp': 1712283571.2330856}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 276. Dropping entry: {'time/batch': 204, 'time/sample': 52224, 'time/batch_in_epoch': 9, 'time/sample_in_epoch': 2304, '_timestamp': 1712283571.2339685}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.2666588}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002977827563881874, '_timestamp': 1712283571.2668512}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 204 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.2681844}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.060769230769231e-05, '_timestamp': 1712283571.2686863}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 276. Dropping entry: {'time/batch': 205, 'time/sample': 52480, 'time/batch_in_epoch': 10, 'time/sample_in_epoch': 2560, '_timestamp': 1712283571.269394}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.34436}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0030269501730799675, '_timestamp': 1712283571.3445563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 205 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.345865}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0550769230769232e-05, '_timestamp': 1712283571.3463695}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 276. Dropping entry: {'time/batch': 206, 'time/sample': 52736, 'time/batch_in_epoch': 11, 'time/sample_in_epoch': 2816, '_timestamp': 1712283571.3473356}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.3762808}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003205740824341774, '_timestamp': 1712283571.3764765}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 206 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.377822}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0493846153846154e-05, '_timestamp': 1712283571.3783567}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 276. Dropping entry: {'time/batch': 207, 'time/sample': 52992, 'time/batch_in_epoch': 12, 'time/sample_in_epoch': 3072, '_timestamp': 1712283571.3790042}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.449825}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0028213136829435825, '_timestamp': 1712283571.4500346}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 207 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.451368}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0436923076923078e-05, '_timestamp': 1712283571.4518592}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 276. Dropping entry: {'time/batch': 208, 'time/sample': 53248, 'time/batch_in_epoch': 13, 'time/sample_in_epoch': 3328, '_timestamp': 1712283571.4527366}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.5324445}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0033805910497903824, '_timestamp': 1712283571.532639}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 208 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.5339553}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.038e-05, '_timestamp': 1712283571.5344546}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 276. Dropping entry: {'time/batch': 209, 'time/sample': 53504, 'time/batch_in_epoch': 14, 'time/sample_in_epoch': 3584, '_timestamp': 1712283571.5351799}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.5636225}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004069267772138119, '_timestamp': 1712283571.5638537}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 209 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.5653195}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0323076923076925e-05, '_timestamp': 1712283571.5658355}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0023827545810490847, 'l2_norm/param/network.bn1.weight': 1.1128672361373901, 'l2_norm/update/network.bn1.weight': 0.0002879513194784522, 'l2_norm/grad/network.bn1.weight': 0.011481528170406818, 'l2_norm/moment/network.bn1.bias': 0.0018516419222578406, 'l2_norm/param/network.bn1.bias': 0.942632257938385, 'l2_norm/update/network.bn1.bias': 0.00024199213657993823, 'l2_norm/grad/network.bn1.bias': 0.007209911942481995, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.0016264664009213448, 'l2_norm/param/network.layer1.0.bn1.weight': 1.151300311088562, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00029511499451473355, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.007964036427438259, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.0012267334386706352, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6900283098220825, 'l2_norm/update/network.layer1.0.bn1.bias': 0.00018296534835826606, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.005657474510371685, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.002039272803813219, 'l2_norm/param/network.layer1.0.bn2.weight': 1.4039411544799805, 'l2_norm/update/network.layer1.0.bn2.weight': 0.00036480839480645955, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.009495781734585762, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0013303490122780204, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7209384441375732, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00018684662063606083, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.004942328203469515, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.0017398132476955652, 'l2_norm/param/network.layer1.1.bn1.weight': 1.412325143814087, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00036500455462373793, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.00988756399601698, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0014095527585595846, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6112786531448364, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00015565045760013163, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.007542057894170284, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0016074919840320945, 'l2_norm/param/network.layer1.1.bn2.weight': 1.3223179578781128, 'l2_norm/update/network.layer1.1.bn2.weight': 0.000339049962349236, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.008599863387644291, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.00076787278521806, 'l2_norm/param/network.layer1.1.bn2.bias': 0.9036840200424194, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00023263991170097142, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.0049944426864385605, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.002217001747339964, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6356687545776367, 'l2_norm/update/network.layer2.0.bn1.weight': 0.0004224056319799274, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.013215298764407635, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0015769536839798093, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7538703083992004, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00019436795264482498, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.008715786971151829, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.002832655794918537, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9340095520019531, 'l2_norm/update/network.layer2.0.bn2.weight': 0.0004996375064365566, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.014146310277283192, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.0017744931392371655, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6671183705329895, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00017314688011538237, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.008559750393033028, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.002737457398325205, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.4148918390274048, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.000366957247024402, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.013851398602128029, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.0017744931392371655, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6671183705329895, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00017314688011538237, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.008559750393033028, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.002901605097576976, 'l2_norm/param/network.layer2.1.bn1.weight': 1.6055654287338257, 'l2_norm/update/network.layer2.1.bn1.weight': 0.0004154892812948674, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.018026569858193398, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.001685381750576198, 'l2_norm/param/network.layer2.1.bn1.bias': 1.402686357498169, 'l2_norm/update/network.layer2.1.bn1.bias': 0.0003618215268943459, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.009470048360526562, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0025480100885033607, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4760385751724243, 'l2_norm/update/network.layer2.1.bn2.weight': 0.0003823999431915581, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.014350363053381443, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0014991936041042209, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9163498878479004, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00023395493917632848, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.008202821016311646, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.0037853235844522715, 'l2_norm/param/network.layer3.0.bn1.weight': 2.249927520751953, 'l2_norm/update/network.layer3.0.bn1.weight': 0.000581498199608177, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.022983431816101074, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.002279997803270817, 'l2_norm/param/network.layer3.0.bn1.bias': 1.3241376876831055, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00034168382990173995, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.012419196777045727, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.004770604893565178, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5406627655029297, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0006551696569658816, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.027795201167464256, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.0025265589356422424, 'l2_norm/param/network.layer3.0.bn2.bias': 1.3976022005081177, 'l2_norm/update/network.layer3.0.bn2.bias': 0.00036385960993357003, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.014160580933094025, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.003719475120306015, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.927548348903656, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00023550604237243533, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.01991909183561802, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.0025265589356422424, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.3976022005081177, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.00036385960993357003, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.014160580933094025, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.004998232703655958, 'l2_norm/param/network.layer3.1.bn1.weight': 2.171694755554199, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0005631824606098235, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.025984929874539375, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.0028877907898277044, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0732028484344482, 'l2_norm/update/network.layer3.1.bn1.bias': 0.0005337994080036879, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.015112308785319328, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0022122422233223915, 'l2_norm/param/network.layer3.1.bn2.weight': 1.978285789489746, 'l2_norm/update/network.layer3.1.bn2.weight': 0.0005147891934029758, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.013084479607641697, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.0014956677332520485, 'l2_norm/param/network.layer3.1.bn2.bias': 1.6336627006530762, 'l2_norm/update/network.layer3.1.bn2.bias': 0.000424165598815307, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.008567378856241703, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0025440833996981382, 'l2_norm/param/network.layer4.0.bn1.weight': 1.449198842048645, 'l2_norm/update/network.layer4.0.bn1.weight': 0.00038059480721130967, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.013877288438379765, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.0018393878126516938, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9997200965881348, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00025657902006059885, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.011857832781970501, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0016335032414644957, 'l2_norm/param/network.layer4.0.bn2.weight': 3.9494130611419678, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0011883563129231334, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.002663268242031336, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0007271992508322, 'l2_norm/param/network.layer4.0.bn2.bias': 0.652103066444397, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00021510956867132336, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.003473840421065688, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0005889792810194194, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.921730875968933, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.0005749529809691012, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0019231612095609307, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0007271992508322, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.652103066444397, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00021510956867132336, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.003473840421065688, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.0011817393824458122, 'l2_norm/param/network.layer4.1.bn1.weight': 0.8998517394065857, 'l2_norm/update/network.layer4.1.bn1.weight': 0.0002571574004832655, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.005459128879010677, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0012679448118433356, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17308259010314941, 'l2_norm/update/network.layer4.1.bn1.bias': 6.301774556050077e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.007032500579953194, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.0026812467258423567, 'l2_norm/param/network.layer4.1.bn2.weight': 3.140336751937866, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0010189738823100924, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.003982685040682554, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0009802149143069983, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8896958827972412, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0003162890498060733, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.002979281358420849, 'l2_norm/moment/network.fc.weight': 0.003347862046211958, 'l2_norm/param/network.fc.weight': 5.7198805809021, 'l2_norm/update/network.fc.weight': 0.0017808355623856187, 'l2_norm/grad/network.fc.weight': 0.009165873751044273, 'l2_norm/moment/network.fc.bias': 0.00021180120529606938, 'l2_norm/param/network.fc.bias': 0.09877854585647583, 'l2_norm/update/network.fc.bias': 2.4458042389596812e-05, 'l2_norm/grad/network.fc.bias': 0.0015433334046974778, 'l2_norm/grad/global': 0.07799962162971497, '_timestamp': 1712283571.5737858}).
Epoch: 2ep
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'time/batch': 210, 'time/sample': 53760, 'time/batch_in_epoch': 15, 'time/sample_in_epoch': 3840, '_timestamp': 1712283571.5758169}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.642359}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003066951408982277, '_timestamp': 1712283571.642581}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 210 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.643994}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0266153846153845e-05, '_timestamp': 1712283571.644516}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 276. Dropping entry: {'time/batch': 211, 'time/sample': 54016, 'time/batch_in_epoch': 16, 'time/sample_in_epoch': 4096, '_timestamp': 1712283571.6451757}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.673385}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002704110462218523, '_timestamp': 1712283571.6735952}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 211 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.675054}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0209230769230771e-05, '_timestamp': 1712283571.6756134}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 276. Dropping entry: {'time/batch': 212, 'time/sample': 54272, 'time/batch_in_epoch': 17, 'time/sample_in_epoch': 4352, '_timestamp': 1712283571.6765096}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.748915}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002992426510900259, '_timestamp': 1712283571.749118}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 212 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.7506301}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0152307692307692e-05, '_timestamp': 1712283571.7511272}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 276. Dropping entry: {'time/batch': 213, 'time/sample': 54528, 'time/batch_in_epoch': 18, 'time/sample_in_epoch': 4608, '_timestamp': 1712283571.7518194}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.8309684}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0020805522799491882, '_timestamp': 1712283571.8314507}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 213 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.8331354}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0095384615384616e-05, '_timestamp': 1712283571.8336432}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 276. Dropping entry: {'time/batch': 214, 'time/sample': 54784, 'time/batch_in_epoch': 19, 'time/sample_in_epoch': 4864, '_timestamp': 1712283571.834537}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.8621013}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0037022246979177, '_timestamp': 1712283571.8622932}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 214 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.8636}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 1.0038461538461539e-05, '_timestamp': 1712283571.8641093}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 276. Dropping entry: {'time/batch': 215, 'time/sample': 55040, 'time/batch_in_epoch': 20, 'time/sample_in_epoch': 5120, '_timestamp': 1712283571.8647208}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.936811}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0022539887577295303, '_timestamp': 1712283571.937018}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 215 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.9401808}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.981538461538463e-06, '_timestamp': 1712283571.9408875}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 276. Dropping entry: {'time/batch': 216, 'time/sample': 55296, 'time/batch_in_epoch': 21, 'time/sample_in_epoch': 5376, '_timestamp': 1712283571.941775}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283571.9701376}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003736785613000393, '_timestamp': 1712283571.9703362}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 216 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283571.9716375}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.924615384615385e-06, '_timestamp': 1712283571.9721398}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 276. Dropping entry: {'time/batch': 217, 'time/sample': 55552, 'time/batch_in_epoch': 22, 'time/sample_in_epoch': 5632, '_timestamp': 1712283571.972808}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.0411854}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0023953099735081196, '_timestamp': 1712283572.0413775}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 217 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.0426567}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.867692307692308e-06, '_timestamp': 1712283572.0431576}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 276. Dropping entry: {'time/batch': 218, 'time/sample': 55808, 'time/batch_in_epoch': 23, 'time/sample_in_epoch': 5888, '_timestamp': 1712283572.0442402}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.0721526}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004377068020403385, '_timestamp': 1712283572.0723488}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 218 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.0738544}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.810769230769232e-06, '_timestamp': 1712283572.0743577}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 276. Dropping entry: {'time/batch': 219, 'time/sample': 56064, 'time/batch_in_epoch': 24, 'time/sample_in_epoch': 6144, '_timestamp': 1712283572.074987}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.151265}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0023739472962915897, '_timestamp': 1712283572.1514635}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 219 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.1527472}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.753846153846156e-06, '_timestamp': 1712283572.1535861}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0022438575979322195, 'l2_norm/param/network.bn1.weight': 1.1100667715072632, 'l2_norm/update/network.bn1.weight': 0.00026951308245770633, 'l2_norm/grad/network.bn1.weight': 0.003946875222027302, 'l2_norm/moment/network.bn1.bias': 0.00163844448979944, 'l2_norm/param/network.bn1.bias': 0.9402472376823425, 'l2_norm/update/network.bn1.bias': 0.0002285895316163078, 'l2_norm/grad/network.bn1.bias': 0.004405430052429438, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.0011390330037102103, 'l2_norm/param/network.layer1.0.bn1.weight': 1.1483925580978394, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00028017169097438455, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.0028569900896400213, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.0011003189720213413, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6883176565170288, 'l2_norm/update/network.layer1.0.bn1.bias': 0.0001673026563366875, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.0026763060595840216, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.001350178848952055, 'l2_norm/param/network.layer1.0.bn2.weight': 1.400427222251892, 'l2_norm/update/network.layer1.0.bn2.weight': 0.00034418870927765965, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.0029415308963507414, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0010206092847511172, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7191324830055237, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00017483004194218665, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.0026333371642977, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.0018598540918901563, 'l2_norm/param/network.layer1.1.bn1.weight': 1.4087779521942139, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00034376076655462384, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.004538050387054682, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0014254339039325714, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6097236275672913, 'l2_norm/update/network.layer1.1.bn1.bias': 0.0001475883909733966, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.004134851507842541, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0017713679699227214, 'l2_norm/param/network.layer1.1.bn2.weight': 1.3189828395843506, 'l2_norm/update/network.layer1.1.bn2.weight': 0.0003213816962670535, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.003593417350202799, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.0008742624777369201, 'l2_norm/param/network.layer1.1.bn2.bias': 0.9014139771461487, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00022066946257837117, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.002101409947499633, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.0020763538777828217, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6315516233444214, 'l2_norm/update/network.layer2.0.bn1.weight': 0.0003983223286923021, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.005430996417999268, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0013589547015726566, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7519773244857788, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00018322393589187413, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.003962462302297354, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.0027693926822394133, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9291502237319946, 'l2_norm/update/network.layer2.0.bn2.weight': 0.00047060506767593324, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.006198105402290821, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.001416179584339261, 'l2_norm/param/network.layer2.0.bn2.bias': 0.665450394153595, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00016526000399608165, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.003948061261326075, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.0021143092308193445, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.4113287925720215, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.000344034779118374, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.004777027294039726, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.001416179584339261, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.665450394153595, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00016526000399608165, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.003948061261326075, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.0028191383462399244, 'l2_norm/param/network.layer2.1.bn1.weight': 1.6015328168869019, 'l2_norm/update/network.layer2.1.bn1.weight': 0.0003902822791133076, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.008251368999481201, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.0014246732462197542, 'l2_norm/param/network.layer2.1.bn1.bias': 1.3991535902023315, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00034239128581248224, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.004561441484838724, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0021414016373455524, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4723392724990845, 'l2_norm/update/network.layer2.1.bn2.weight': 0.00036031095078215003, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.005067996680736542, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0013530653668567538, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9140313863754272, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00022424822964239866, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.0034567357506603003, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.0037269338499754667, 'l2_norm/param/network.layer3.0.bn1.weight': 2.2442715167999268, 'l2_norm/update/network.layer3.0.bn1.weight': 0.0005477453814819455, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.00935886800289154, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.0021804014686495066, 'l2_norm/param/network.layer3.0.bn1.bias': 1.320806860923767, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00032355778967030346, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.00600905017927289, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.00529109314084053, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5342657566070557, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0006165755912661552, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.011607624590396881, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.002734893700107932, 'l2_norm/param/network.layer3.0.bn2.bias': 1.3941148519515991, 'l2_norm/update/network.layer3.0.bn2.bias': 0.00034585371031425893, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.006791982334107161, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.0034624366089701653, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9251664876937866, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.0002222133189206943, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.009398551657795906, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.002734893700107932, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.3941148519515991, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.00034585371031425893, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.006791982334107161, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.0052580200135707855, 'l2_norm/param/network.layer3.1.bn1.weight': 2.166245222091675, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0005290728877298534, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.013646886684000492, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.0027681111823767424, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0679893493652344, 'l2_norm/update/network.layer3.1.bn1.bias': 0.0005060947150923312, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.007638663984835148, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0022542481310665607, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9733569622039795, 'l2_norm/update/network.layer3.1.bn2.weight': 0.0004864207876380533, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.007851896807551384, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.0014105747686699033, 'l2_norm/param/network.layer3.1.bn2.bias': 1.6295661926269531, 'l2_norm/update/network.layer3.1.bn2.bias': 0.0003998447791673243, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.00484615471214056, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0024928187485784292, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4455995559692383, 'l2_norm/update/network.layer4.0.bn1.weight': 0.0003591055574361235, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.00799587182700634, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.001863866113126278, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9971672296524048, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00024211379059124738, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.006175984162837267, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0015988856321200728, 'l2_norm/param/network.layer4.0.bn2.weight': 3.9411003589630127, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0011182146845385432, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.00167373800650239, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.000735812122002244, 'l2_norm/param/network.layer4.0.bn2.bias': 0.6509036421775818, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00020480770035646856, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0013996255584061146, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0006307709263637662, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.9176493883132935, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.0005432334146462381, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0009632526198402047, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.000735812122002244, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.6509036421775818, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00020480770035646856, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0013996255584061146, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.001350770122371614, 'l2_norm/param/network.layer4.1.bn1.weight': 0.8978013396263123, 'l2_norm/update/network.layer4.1.bn1.weight': 0.00024390868202317506, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.0027225767262279987, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.00172115967143327, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17269901931285858, 'l2_norm/update/network.layer4.1.bn1.bias': 7.237692625494674e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.0030517694540321827, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.0026660109870135784, 'l2_norm/param/network.layer4.1.bn2.weight': 3.13442063331604, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0009601889178156853, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.0025876036379486322, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0009752617334015667, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8882777690887451, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0003004940808750689, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.001240055775269866, 'l2_norm/moment/network.fc.weight': 0.003395387204363942, 'l2_norm/param/network.fc.weight': 5.708271026611328, 'l2_norm/update/network.fc.weight': 0.0016771467635408044, 'l2_norm/grad/network.fc.weight': 0.004411900881677866, 'l2_norm/moment/network.fc.bias': 0.00025327078765258193, 'l2_norm/param/network.fc.bias': 0.09851326048374176, 'l2_norm/update/network.fc.bias': 2.3163460355135612e-05, 'l2_norm/grad/network.fc.bias': 0.000558831263333559, 'l2_norm/grad/global': 0.036169927567243576, '_timestamp': 1712283572.1619477}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'time/batch': 220, 'time/sample': 56320, 'time/batch_in_epoch': 25, 'time/sample_in_epoch': 6400, '_timestamp': 1712283572.1637495}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.2359967}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0020195250399410725, '_timestamp': 1712283572.2361922}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 220 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.2377386}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.696923076923077e-06, '_timestamp': 1712283572.2382503}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 276. Dropping entry: {'time/batch': 221, 'time/sample': 56576, 'time/batch_in_epoch': 26, 'time/sample_in_epoch': 6656, '_timestamp': 1712283572.2389565}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.265773}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002533621620386839, '_timestamp': 1712283572.2660887}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 221 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.2675505}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.640000000000001e-06, '_timestamp': 1712283572.2680817}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 276. Dropping entry: {'time/batch': 222, 'time/sample': 56832, 'time/batch_in_epoch': 27, 'time/sample_in_epoch': 6912, '_timestamp': 1712283572.2689147}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.343022}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003367780242115259, '_timestamp': 1712283572.3433433}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 222 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.3452663}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.583076923076923e-06, '_timestamp': 1712283572.3458164}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 276. Dropping entry: {'time/batch': 223, 'time/sample': 57088, 'time/batch_in_epoch': 28, 'time/sample_in_epoch': 7168, '_timestamp': 1712283572.3464072}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.373086}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0025580599904060364, '_timestamp': 1712283572.3734193}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 223 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.3757358}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.526153846153847e-06, '_timestamp': 1712283572.376318}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 276. Dropping entry: {'time/batch': 224, 'time/sample': 57344, 'time/batch_in_epoch': 29, 'time/sample_in_epoch': 7424, '_timestamp': 1712283572.3774624}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.4504387}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0040655541233718395, '_timestamp': 1712283572.450688}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 224 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.4520411}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.469230769230768e-06, '_timestamp': 1712283572.4525404}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 276. Dropping entry: {'time/batch': 225, 'time/sample': 57600, 'time/batch_in_epoch': 30, 'time/sample_in_epoch': 7680, '_timestamp': 1712283572.4532042}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.532935}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0037931380793452263, '_timestamp': 1712283572.5331383}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 225 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.5346372}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.412307692307694e-06, '_timestamp': 1712283572.5351486}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 276. Dropping entry: {'time/batch': 226, 'time/sample': 57856, 'time/batch_in_epoch': 31, 'time/sample_in_epoch': 7936, '_timestamp': 1712283572.5360427}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.5625572}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004676546435803175, '_timestamp': 1712283572.562752}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 226 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.5640795}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.355384615384617e-06, '_timestamp': 1712283572.5645823}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 276. Dropping entry: {'time/batch': 227, 'time/sample': 58112, 'time/batch_in_epoch': 32, 'time/sample_in_epoch': 8192, '_timestamp': 1712283572.565191}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.6353455}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0025183996185660362, '_timestamp': 1712283572.6355367}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 227 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.6368334}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.298461538461539e-06, '_timestamp': 1712283572.637533}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 276. Dropping entry: {'time/batch': 228, 'time/sample': 58368, 'time/batch_in_epoch': 33, 'time/sample_in_epoch': 8448, '_timestamp': 1712283572.6389856}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.6670165}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004103135317564011, '_timestamp': 1712283572.667252}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 228 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.668658}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.241538461538461e-06, '_timestamp': 1712283572.6691632}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 276. Dropping entry: {'time/batch': 229, 'time/sample': 58624, 'time/batch_in_epoch': 34, 'time/sample_in_epoch': 8704, '_timestamp': 1712283572.6698267}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.745916}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0027146986685693264, '_timestamp': 1712283572.7461135}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 229 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.7474456}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.184615384615386e-06, '_timestamp': 1712283572.7479498}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0024380593094974756, 'l2_norm/param/network.bn1.weight': 1.1074057817459106, 'l2_norm/update/network.bn1.weight': 0.000252585276030004, 'l2_norm/grad/network.bn1.weight': 0.005284637212753296, 'l2_norm/moment/network.bn1.bias': 0.001697902800515294, 'l2_norm/param/network.bn1.bias': 0.938016951084137, 'l2_norm/update/network.bn1.bias': 0.00021564365306403488, 'l2_norm/grad/network.bn1.bias': 0.003363995347172022, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.0016298795817419887, 'l2_norm/param/network.layer1.0.bn1.weight': 1.14566969871521, 'l2_norm/update/network.layer1.0.bn1.weight': 0.0002643924090079963, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.003800732083618641, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.001509768539108336, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6866775751113892, 'l2_norm/update/network.layer1.0.bn1.bias': 0.00015642332436982542, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.003118005581200123, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.0017738286405801773, 'l2_norm/param/network.layer1.0.bn2.weight': 1.3971314430236816, 'l2_norm/update/network.layer1.0.bn2.weight': 0.0003228634304832667, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.004128499422222376, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0013950422871857882, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7174153923988342, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00016468239482492208, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.002537225605919957, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.00238142441958189, 'l2_norm/param/network.layer1.1.bn1.weight': 1.405437707901001, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00032301971805281937, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.0039485967718064785, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.002381357131525874, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6082714200019836, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00014185810869093984, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.002956705167889595, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0016662783455103636, 'l2_norm/param/network.layer1.1.bn2.weight': 1.315850853919983, 'l2_norm/update/network.layer1.1.bn2.weight': 0.000301315012620762, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.0047490415163338184, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.001470094663091004, 'l2_norm/param/network.layer1.1.bn2.bias': 0.899299681186676, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00021098482829984277, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.002920374274253845, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.0029617620166391134, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6276822090148926, 'l2_norm/update/network.layer2.0.bn1.weight': 0.00037491758121177554, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.006194745190441608, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0020146819297224283, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7501988410949707, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00017336577002424747, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.003951417747884989, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.0034781366121023893, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9245764017105103, 'l2_norm/update/network.layer2.0.bn2.weight': 0.00044285639887675643, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.006160194985568523, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.002177863148972392, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6638821959495544, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00015443093434441835, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.004146041348576546, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.0030142893083393574, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.407981276512146, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.00032484575058333576, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.00643873680382967, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.002177863148972392, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6638821959495544, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00015443093434441835, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.004146041348576546, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.003829343244433403, 'l2_norm/param/network.layer2.1.bn1.weight': 1.5977327823638916, 'l2_norm/update/network.layer2.1.bn1.weight': 0.00036768955760635436, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.007186245173215866, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.002179260365664959, 'l2_norm/param/network.layer2.1.bn1.bias': 1.3958368301391602, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00032096815994009376, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.004234494641423225, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.003030159743502736, 'l2_norm/param/network.layer2.1.bn2.weight': 1.468851923942566, 'l2_norm/update/network.layer2.1.bn2.weight': 0.00033817850635387003, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.005103177856653929, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0017617846606299281, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9118736386299133, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00021307982387952507, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.003549060318619013, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.004976797848939896, 'l2_norm/param/network.layer3.0.bn1.weight': 2.238955497741699, 'l2_norm/update/network.layer3.0.bn1.weight': 0.0005164223839528859, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.010744219645857811, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.0028756847605109215, 'l2_norm/param/network.layer3.0.bn1.bias': 1.3176666498184204, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00030192185658961535, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.0066645885817706585, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.0061176251620054245, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5282418727874756, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0005808355053886771, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.012804540805518627, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.00320861442014575, 'l2_norm/param/network.layer3.0.bn2.bias': 1.3908233642578125, 'l2_norm/update/network.layer3.0.bn2.bias': 0.00032026873668655753, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.007269632536917925, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.004297873470932245, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9229481220245361, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.0002133656817022711, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.009032265283167362, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.00320861442014575, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.3908233642578125, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.00032026873668655753, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.007269632536917925, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.005687118042260408, 'l2_norm/param/network.layer3.1.bn1.weight': 2.161112070083618, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0004972337046638131, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.012662997469305992, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.0033571410458534956, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0630884170532227, 'l2_norm/update/network.layer3.1.bn1.bias': 0.0004748784122057259, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.007210895884782076, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0033746110275387764, 'l2_norm/param/network.layer3.1.bn2.weight': 1.96873939037323, 'l2_norm/update/network.layer3.1.bn2.weight': 0.00046023959293961525, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.0068281651474535465, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.002063179388642311, 'l2_norm/param/network.layer3.1.bn2.bias': 1.6257084608078003, 'l2_norm/update/network.layer3.1.bn2.bias': 0.0003766873851418495, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.004259262699633837, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0031156104523688555, 'l2_norm/param/network.layer4.0.bn1.weight': 1.442201018333435, 'l2_norm/update/network.layer4.0.bn1.weight': 0.0003371943603269756, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.006314694881439209, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.0024850619956851006, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9947724342346191, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00023032711760606617, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.004938085097819567, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0017086539883166552, 'l2_norm/param/network.layer4.0.bn2.weight': 3.9332807064056396, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0010607301956042647, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.001883524120785296, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0009118583402596414, 'l2_norm/param/network.layer4.0.bn2.bias': 0.649776816368103, 'l2_norm/update/network.layer4.0.bn2.bias': 0.0001994087069761008, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0016115158796310425, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0005865381681360304, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.9138050079345703, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.0005094657535664737, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0009186659590341151, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0009118583402596414, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.649776816368103, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.0001994087069761008, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0016115158796310425, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.001579576637595892, 'l2_norm/param/network.layer4.1.bn1.weight': 0.8958728909492493, 'l2_norm/update/network.layer4.1.bn1.weight': 0.0002341785584576428, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.002717450726777315, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0018275618785992265, 'l2_norm/param/network.layer4.1.bn1.bias': 0.1723371297121048, 'l2_norm/update/network.layer4.1.bn1.bias': 7.031046698102728e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.0034450336825102568, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.002762364922091365, 'l2_norm/param/network.layer4.1.bn2.weight': 3.128830909729004, 'l2_norm/update/network.layer4.1.bn2.weight': 0.000907425710465759, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.0026944957207888365, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0010973700555041432, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8869470953941345, 'l2_norm/update/network.layer4.1.bn2.bias': 0.00028867259970866144, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.0016032966086640954, 'l2_norm/moment/network.fc.weight': 0.0035772807896137238, 'l2_norm/param/network.fc.weight': 5.697320461273193, 'l2_norm/update/network.fc.weight': 0.001586924190632999, 'l2_norm/grad/network.fc.weight': 0.004801953677088022, 'l2_norm/moment/network.fc.bias': 0.00033950101351365447, 'l2_norm/param/network.fc.bias': 0.0982682853937149, 'l2_norm/update/network.fc.bias': 2.330320239707362e-05, 'l2_norm/grad/network.fc.bias': 0.0006847226759418845, 'l2_norm/grad/global': 0.036509618163108826, '_timestamp': 1712283572.7556155}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'time/batch': 230, 'time/sample': 58880, 'time/batch_in_epoch': 35, 'time/sample_in_epoch': 8960, '_timestamp': 1712283572.757617}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.8326323}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'loss/train/total': 0.00383857823908329, '_timestamp': 1712283572.8328304}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 230 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.8341331}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.127692307692308e-06, '_timestamp': 1712283572.8346317}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 276. Dropping entry: {'time/batch': 231, 'time/sample': 59136, 'time/batch_in_epoch': 36, 'time/sample_in_epoch': 9216, '_timestamp': 1712283572.8352458}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.86183}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002941870130598545, '_timestamp': 1712283572.862036}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 231 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.8633544}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.07076923076923e-06, '_timestamp': 1712283572.8638594}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 276. Dropping entry: {'time/batch': 232, 'time/sample': 59392, 'time/batch_in_epoch': 37, 'time/sample_in_epoch': 9472, '_timestamp': 1712283572.8647249}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.936827}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002689747139811516, '_timestamp': 1712283572.9370346}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 232 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.938546}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 9.013846153846155e-06, '_timestamp': 1712283572.939059}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 276. Dropping entry: {'time/batch': 233, 'time/sample': 59648, 'time/batch_in_epoch': 38, 'time/sample_in_epoch': 9728, '_timestamp': 1712283572.9397154}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283572.967437}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0022147130221128464, '_timestamp': 1712283572.9676893}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 233 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283572.9690778}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.956923076923079e-06, '_timestamp': 1712283572.9695756}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 276. Dropping entry: {'time/batch': 234, 'time/sample': 59904, 'time/batch_in_epoch': 39, 'time/sample_in_epoch': 9984, '_timestamp': 1712283572.970646}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.048688}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0027135247364640236, '_timestamp': 1712283573.0490947}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 234 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.0504105}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.9e-06, '_timestamp': 1712283573.0509064}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 276. Dropping entry: {'time/batch': 235, 'time/sample': 60160, 'time/batch_in_epoch': 40, 'time/sample_in_epoch': 10240, '_timestamp': 1712283573.0515084}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.077745}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0033658742904663086, '_timestamp': 1712283573.077951}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 235 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.0792532}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.843076923076925e-06, '_timestamp': 1712283573.079749}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 276. Dropping entry: {'time/batch': 236, 'time/sample': 60416, 'time/batch_in_epoch': 41, 'time/sample_in_epoch': 10496, '_timestamp': 1712283573.0806715}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.1534736}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004485780838876963, '_timestamp': 1712283573.1536646}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 236 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.1561503}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.786153846153846e-06, '_timestamp': 1712283573.1569579}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 276. Dropping entry: {'time/batch': 237, 'time/sample': 60672, 'time/batch_in_epoch': 42, 'time/sample_in_epoch': 10752, '_timestamp': 1712283573.157739}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.235683}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 276. Dropping entry: {'loss/train/total': 0.00352270994335413, '_timestamp': 1712283573.2358813}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 237 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.237223}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.72923076923077e-06, '_timestamp': 1712283573.2377167}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 276. Dropping entry: {'time/batch': 238, 'time/sample': 60928, 'time/batch_in_epoch': 43, 'time/sample_in_epoch': 11008, '_timestamp': 1712283573.2385914}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.2653265}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004251232836395502, '_timestamp': 1712283573.2655227}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 238 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.2668421}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.672307692307693e-06, '_timestamp': 1712283573.2673483}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 276. Dropping entry: {'time/batch': 239, 'time/sample': 61184, 'time/batch_in_epoch': 44, 'time/sample_in_epoch': 11264, '_timestamp': 1712283573.2679658}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.3444135}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 276. Dropping entry: {'loss/train/total': 0.005399457644671202, '_timestamp': 1712283573.344612}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 239 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.3462243}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.615384615384617e-06, '_timestamp': 1712283573.3467212}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0036789458245038986, 'l2_norm/param/network.bn1.weight': 1.1049299240112305, 'l2_norm/update/network.bn1.weight': 0.00024255484458990395, 'l2_norm/grad/network.bn1.weight': 0.035579875111579895, 'l2_norm/moment/network.bn1.bias': 0.003769906237721443, 'l2_norm/param/network.bn1.bias': 0.9359298944473267, 'l2_norm/update/network.bn1.bias': 0.0002016650978475809, 'l2_norm/grad/network.bn1.bias': 0.03209349885582924, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.00444904575124383, 'l2_norm/param/network.layer1.0.bn1.weight': 1.1431224346160889, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00024990818928927183, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.031997133046388626, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.003997311927378178, 'l2_norm/param/network.layer1.0.bn1.bias': 0.685135006904602, 'l2_norm/update/network.layer1.0.bn1.bias': 0.0001481384679209441, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.027769889682531357, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.004721519071608782, 'l2_norm/param/network.layer1.0.bn2.weight': 1.3940271139144897, 'l2_norm/update/network.layer1.0.bn2.weight': 0.0003026982885785401, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.037646349519491196, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0031152875162661076, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7157989740371704, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00015440827701240778, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.022560250014066696, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.004516214597970247, 'l2_norm/param/network.layer1.1.bn1.weight': 1.4023027420043945, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00030307279666885734, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.03482257202267647, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0028053084388375282, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6069151759147644, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00013222462439443916, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.020444290712475777, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.004296249710023403, 'l2_norm/param/network.layer1.1.bn2.weight': 1.3129017353057861, 'l2_norm/update/network.layer1.1.bn2.weight': 0.0002815275511238724, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.031846098601818085, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.002687112195417285, 'l2_norm/param/network.layer1.1.bn2.bias': 0.8973052501678467, 'l2_norm/update/network.layer1.1.bn2.bias': 0.0001921962684718892, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.020007682964205742, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.00601171562448144, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6240582466125488, 'l2_norm/update/network.layer2.0.bn1.weight': 0.0003541796759236604, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.04959441348910332, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.003967789467424154, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7485225200653076, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00015991026884876192, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.032732896506786346, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.006859593093395233, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9202815294265747, 'l2_norm/update/network.layer2.0.bn2.weight': 0.0004132222384214401, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.04560105875134468, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.004243438132107258, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6624136567115784, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00015054317191243172, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.03029533289372921, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.005624663550406694, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.404840350151062, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.0003063567273784429, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.04579877853393555, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.004243438132107258, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6624136567115784, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00015054317191243172, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.03029533289372921, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.008416302502155304, 'l2_norm/param/network.layer2.1.bn1.weight': 1.5941598415374756, 'l2_norm/update/network.layer2.1.bn1.weight': 0.0003466252819634974, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.06246788799762726, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.0044519416987895966, 'l2_norm/param/network.layer2.1.bn1.bias': 1.3927425146102905, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00030257925391197205, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.033685337752103806, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0049929264932870865, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4655587673187256, 'l2_norm/update/network.layer2.1.bn2.weight': 0.00031501767807640135, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.03840306028723717, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0038537252694368362, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9098713397979736, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00019886963127646595, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.02984451688826084, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.008009831421077251, 'l2_norm/param/network.layer3.0.bn1.weight': 2.2339656352996826, 'l2_norm/update/network.layer3.0.bn1.weight': 0.00048297239118255675, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.05920219048857689, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.005458557512611151, 'l2_norm/param/network.layer3.0.bn1.bias': 1.3147298097610474, 'l2_norm/update/network.layer3.0.bn1.bias': 0.0002897184167522937, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.04189147427678108, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.0111225675791502, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5225982666015625, 'l2_norm/update/network.layer3.0.bn2.weight': 0.000544098555110395, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.07963912934064865, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.006042405031621456, 'l2_norm/param/network.layer3.0.bn2.bias': 1.387722134590149, 'l2_norm/update/network.layer3.0.bn2.bias': 0.00030412725755013525, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.0464714840054512, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.0075874533504247665, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9208707809448242, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00020363701332826167, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.06177888065576553, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.006042405031621456, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.387722134590149, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.00030412725755013525, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.0464714840054512, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.01221302431076765, 'l2_norm/param/network.layer3.1.bn1.weight': 2.1562886238098145, 'l2_norm/update/network.layer3.1.bn1.weight': 0.00046464288607239723, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.09279604256153107, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.006983143277466297, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0584912300109863, 'l2_norm/update/network.layer3.1.bn1.bias': 0.000449193874374032, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.05763627961277962, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.00530242919921875, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9643973112106323, 'l2_norm/update/network.layer3.1.bn2.weight': 0.00042896962258964777, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.04592510685324669, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.0034118497278541327, 'l2_norm/param/network.layer3.1.bn2.bias': 1.622102975845337, 'l2_norm/update/network.layer3.1.bn2.bias': 0.00035696191480383277, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.028503986075520515, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.004143949132412672, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4390119314193726, 'l2_norm/update/network.layer4.0.bn1.weight': 0.0003174254088662565, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.026829125359654427, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.00334915635176003, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9925285577774048, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00022045867808628827, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.024878740310668945, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0017454370390623808, 'l2_norm/param/network.layer4.0.bn2.weight': 3.925973415374756, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0009934218833222985, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.0037445782218128443, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0009098388254642487, 'l2_norm/param/network.layer4.0.bn2.bias': 0.6487247347831726, 'l2_norm/update/network.layer4.0.bn2.bias': 0.0001815947180148214, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.007251114584505558, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0006587265525013208, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.9102228879928589, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.0004750209045596421, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0043778810650110245, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0009098388254642487, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.6487247347831726, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.0001815947180148214, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.007251114584505558, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.0019246499286964536, 'l2_norm/param/network.layer4.1.bn1.weight': 0.89410001039505, 'l2_norm/update/network.layer4.1.bn1.weight': 0.00022211336181499064, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.01084991730749607, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0025443374179303646, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17196357250213623, 'l2_norm/update/network.layer4.1.bn1.bias': 8.009633893379942e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.016785522922873497, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.0028071575798094273, 'l2_norm/param/network.layer4.1.bn2.weight': 3.1236002445220947, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0008490371401421726, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.004806636832654476, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0010511238360777497, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8857139348983765, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0002680980251170695, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.004726003855466843, 'l2_norm/moment/network.fc.weight': 0.00362084130756557, 'l2_norm/param/network.fc.weight': 5.687090873718262, 'l2_norm/update/network.fc.weight': 0.0014859848888590932, 'l2_norm/grad/network.fc.weight': 0.015487659722566605, 'l2_norm/moment/network.fc.bias': 0.00024544939515180886, 'l2_norm/param/network.fc.bias': 0.09803611040115356, 'l2_norm/update/network.fc.bias': 2.2745585738448426e-05, 'l2_norm/grad/network.fc.bias': 0.0025297170504927635, 'l2_norm/grad/global': 0.25053781270980835, '_timestamp': 1712283573.3544176}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'time/batch': 240, 'time/sample': 61440, 'time/batch_in_epoch': 45, 'time/sample_in_epoch': 11520, '_timestamp': 1712283573.356277}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.383099}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0028013535775244236, '_timestamp': 1712283573.3832912}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 240 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.3845885}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.55846153846154e-06, '_timestamp': 1712283573.3850772}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 276. Dropping entry: {'time/batch': 241, 'time/sample': 61696, 'time/batch_in_epoch': 46, 'time/sample_in_epoch': 11776, '_timestamp': 1712283573.3857505}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.454752}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003351384773850441, '_timestamp': 1712283573.4549606}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 241 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.4562638}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.501538461538462e-06, '_timestamp': 1712283573.456747}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 276. Dropping entry: {'time/batch': 242, 'time/sample': 61952, 'time/batch_in_epoch': 47, 'time/sample_in_epoch': 12032, '_timestamp': 1712283573.4576018}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.5333405}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002104134764522314, '_timestamp': 1712283573.5335345}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 242 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.5351183}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.444615384615386e-06, '_timestamp': 1712283573.5356185}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 276. Dropping entry: {'time/batch': 243, 'time/sample': 62208, 'time/batch_in_epoch': 48, 'time/sample_in_epoch': 12288, '_timestamp': 1712283573.536454}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.5636687}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004317942541092634, '_timestamp': 1712283573.563862}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 243 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.5652385}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.387692307692308e-06, '_timestamp': 1712283573.5657387}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 276. Dropping entry: {'time/batch': 244, 'time/sample': 62464, 'time/batch_in_epoch': 49, 'time/sample_in_epoch': 12544, '_timestamp': 1712283573.5666425}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.6354477}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0025153812021017075, '_timestamp': 1712283573.6356359}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 244 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.6371248}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.33076923076923e-06, '_timestamp': 1712283573.6376176}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 276. Dropping entry: {'time/batch': 245, 'time/sample': 62720, 'time/batch_in_epoch': 50, 'time/sample_in_epoch': 12800, '_timestamp': 1712283573.6383362}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.6653574}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 276. Dropping entry: {'loss/train/total': 0.004298774525523186, '_timestamp': 1712283573.6655438}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 245 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.666806}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.273846153846155e-06, '_timestamp': 1712283573.6672995}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 276. Dropping entry: {'time/batch': 246, 'time/sample': 62976, 'time/batch_in_epoch': 51, 'time/sample_in_epoch': 13056, '_timestamp': 1712283573.668149}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.746515}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0035112164914608, '_timestamp': 1712283573.746707}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 246 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.7483056}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.216923076923077e-06, '_timestamp': 1712283573.7490196}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 276. Dropping entry: {'time/batch': 247, 'time/sample': 63232, 'time/batch_in_epoch': 52, 'time/sample_in_epoch': 13312, '_timestamp': 1712283573.7497318}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.776353}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002653685864061117, '_timestamp': 1712283573.7765417}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 247 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.7781205}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.160000000000001e-06, '_timestamp': 1712283573.778788}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 276. Dropping entry: {'time/batch': 248, 'time/sample': 63488, 'time/batch_in_epoch': 53, 'time/sample_in_epoch': 13568, '_timestamp': 1712283573.7800655}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.8577867}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0044578006491065025, '_timestamp': 1712283573.858016}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 248 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.8594584}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.103076923076922e-06, '_timestamp': 1712283573.8599768}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 276. Dropping entry: {'time/batch': 249, 'time/sample': 63744, 'time/batch_in_epoch': 54, 'time/sample_in_epoch': 13824, '_timestamp': 1712283573.860711}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.9357784}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0027427845634520054, '_timestamp': 1712283573.9359775}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 249 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.9372594}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 8.046153846153848e-06, '_timestamp': 1712283573.9377584}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.003511903341859579, 'l2_norm/param/network.bn1.weight': 1.1026617288589478, 'l2_norm/update/network.bn1.weight': 0.00022579613141715527, 'l2_norm/grad/network.bn1.weight': 0.0031948955729603767, 'l2_norm/moment/network.bn1.bias': 0.0028384351171553135, 'l2_norm/param/network.bn1.bias': 0.9339549541473389, 'l2_norm/update/network.bn1.bias': 0.0001865210069809109, 'l2_norm/grad/network.bn1.bias': 0.002342446008697152, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.002582239918410778, 'l2_norm/param/network.layer1.0.bn1.weight': 1.140745759010315, 'l2_norm/update/network.layer1.0.bn1.weight': 0.0002316476166015491, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.0026919508818536997, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.0019972934387624264, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6836866736412048, 'l2_norm/update/network.layer1.0.bn1.bias': 0.00013732419756706804, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.002080753678455949, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.003105888608843088, 'l2_norm/param/network.layer1.0.bn2.weight': 1.3910998106002808, 'l2_norm/update/network.layer1.0.bn2.weight': 0.0002779684728011489, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.0024335221387445927, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0019386551575735211, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7143083810806274, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00014591995568480343, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.002218802459537983, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.002918771468102932, 'l2_norm/param/network.layer1.1.bn1.weight': 1.399370789527893, 'l2_norm/update/network.layer1.1.bn1.weight': 0.0002817212953232229, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.004548113793134689, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0019029674585908651, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6056395769119263, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00012303127732593566, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.0037165989633649588, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0030544749461114407, 'l2_norm/param/network.layer1.1.bn2.weight': 1.310149073600769, 'l2_norm/update/network.layer1.1.bn2.weight': 0.00026370296836830676, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.003313801484182477, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.0018282931996509433, 'l2_norm/param/network.layer1.1.bn2.bias': 0.8954306840896606, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00018239721248392016, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.002126736333593726, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.004091470967978239, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6206787824630737, 'l2_norm/update/network.layer2.0.bn1.weight': 0.000327365065459162, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.003908762242645025, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0026434350293129683, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7469310164451599, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00015079379954840988, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.00288019934669137, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.004347552545368671, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9162607192993164, 'l2_norm/update/network.layer2.0.bn2.weight': 0.00038683295133523643, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.005396787542849779, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.002895490499213338, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6610339283943176, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00013315767864696681, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.0034736571833491325, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.00418776785954833, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.4019147157669067, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.0002829688019119203, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.004669288173317909, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.002895490499213338, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6610339283943176, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00013315767864696681, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.0034736571833491325, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.00603379774838686, 'l2_norm/param/network.layer2.1.bn1.weight': 1.5908312797546387, 'l2_norm/update/network.layer2.1.bn1.weight': 0.0003214036696590483, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.0060192896053195, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.003262043697759509, 'l2_norm/param/network.layer2.1.bn1.bias': 1.389840006828308, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00028106008539907634, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.0036640495527535677, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0036982144229114056, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4624719619750977, 'l2_norm/update/network.layer2.1.bn2.weight': 0.0002935318916570395, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.003967662807554007, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0027458295226097107, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9079596996307373, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00018272563465870917, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.0026822735089808702, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.005634737201035023, 'l2_norm/param/network.layer3.0.bn1.weight': 2.229297161102295, 'l2_norm/update/network.layer3.0.bn1.weight': 0.00044926858390681446, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.007479428313672543, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.0036014332436025143, 'l2_norm/param/network.layer3.0.bn1.bias': 1.311989665031433, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00026601654826663435, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.004408590961247683, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.007359534502029419, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5173141956329346, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0005059901159256697, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.01044323481619358, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.003999164793640375, 'l2_norm/param/network.layer3.0.bn2.bias': 1.3848352432250977, 'l2_norm/update/network.layer3.0.bn2.bias': 0.0002800919464789331, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.005475615616887808, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.0047074975445866585, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9189285039901733, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00018780732352752239, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.006760964635759592, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.003999164793640375, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.3848352432250977, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.0002800919464789331, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.005475615616887808, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.009426629170775414, 'l2_norm/param/network.layer3.1.bn1.weight': 2.1517741680145264, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0004347131180111319, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.012104369699954987, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.005234366748481989, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0542099475860596, 'l2_norm/update/network.layer3.1.bn1.bias': 0.0004149455635342747, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.006641024257987738, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0037745775189250708, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9603345394134521, 'l2_norm/update/network.layer3.1.bn2.weight': 0.00039933581138029695, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.006283088121563196, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.002176669891923666, 'l2_norm/param/network.layer3.1.bn2.bias': 1.6187374591827393, 'l2_norm/update/network.layer3.1.bn2.bias': 0.000326994777424261, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.003773296717554331, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0035717724822461605, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4360308647155762, 'l2_norm/update/network.layer4.0.bn1.weight': 0.00029614398954436183, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.00544174388051033, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.002584845293313265, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9904407262802124, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00020003544341307133, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.00429582828655839, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0016475648153573275, 'l2_norm/param/network.layer4.0.bn2.weight': 3.9191386699676514, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0009191238787025213, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.0018380283145233989, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0008314455044455826, 'l2_norm/param/network.layer4.0.bn2.bias': 0.6476975083351135, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00016985721595119685, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0017490111058577895, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.000668091292027384, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.906843900680542, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.00045209506060928106, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0012019496643915772, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0008314455044455826, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.6476975083351135, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00016985721595119685, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0017490111058577895, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.0015085519989952445, 'l2_norm/param/network.layer4.1.bn1.weight': 0.892429769039154, 'l2_norm/update/network.layer4.1.bn1.weight': 0.00020296846923884004, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.0026275792624801397, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0022432678379118443, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17164358496665955, 'l2_norm/update/network.layer4.1.bn1.bias': 6.547711382154375e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.0029786494560539722, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.002776189474388957, 'l2_norm/param/network.layer4.1.bn2.weight': 3.1187217235565186, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0007902578799985349, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.003097259672358632, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0010717095574364066, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8845575451850891, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0002518411201890558, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.0018323035910725594, 'l2_norm/moment/network.fc.weight': 0.003509700996801257, 'l2_norm/param/network.fc.weight': 5.677525520324707, 'l2_norm/update/network.fc.weight': 0.001379096182063222, 'l2_norm/grad/network.fc.weight': 0.005657918751239777, 'l2_norm/moment/network.fc.bias': 0.0002949426416307688, 'l2_norm/param/network.fc.bias': 0.0978349894285202, 'l2_norm/update/network.fc.bias': 2.0076020518899895e-05, 'l2_norm/grad/network.fc.bias': 0.0009649022831581533, 'l2_norm/grad/global': 0.030240245163440704, '_timestamp': 1712283573.9470932}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'time/batch': 250, 'time/sample': 64000, 'time/batch_in_epoch': 55, 'time/sample_in_epoch': 14080, '_timestamp': 1712283573.9490309}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283573.975306}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0025000907480716705, '_timestamp': 1712283573.975499}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283573.976785}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.989230769230769e-06, '_timestamp': 1712283573.9772892}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 276. Dropping entry: {'time/batch': 251, 'time/sample': 64256, 'time/batch_in_epoch': 56, 'time/sample_in_epoch': 14336, '_timestamp': 1712283573.9778738}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.0560167}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0026192362420260906, '_timestamp': 1712283574.0562103}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 251 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.0575194}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.932307692307693e-06, '_timestamp': 1712283574.05802}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 276. Dropping entry: {'time/batch': 252, 'time/sample': 64512, 'time/batch_in_epoch': 57, 'time/sample_in_epoch': 14592, '_timestamp': 1712283574.0588467}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.1363602}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002332179807126522, '_timestamp': 1712283574.1365492}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 252 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.1378367}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.875384615384619e-06, '_timestamp': 1712283574.1383462}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 276. Dropping entry: {'time/batch': 253, 'time/sample': 64768, 'time/batch_in_epoch': 58, 'time/sample_in_epoch': 14848, '_timestamp': 1712283574.139052}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.1672852}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0038576689548790455, '_timestamp': 1712283574.1674771}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 253 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.1687818}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.81846153846154e-06, '_timestamp': 1712283574.1692932}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 276. Dropping entry: {'time/batch': 254, 'time/sample': 65024, 'time/batch_in_epoch': 59, 'time/sample_in_epoch': 15104, '_timestamp': 1712283574.1701796}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.243887}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0035846326500177383, '_timestamp': 1712283574.2441082}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 254 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.245609}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.761538461538462e-06, '_timestamp': 1712283574.246134}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 276. Dropping entry: {'time/batch': 255, 'time/sample': 65280, 'time/batch_in_epoch': 60, 'time/sample_in_epoch': 15360, '_timestamp': 1712283574.2467704}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.273771}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003402319736778736, '_timestamp': 1712283574.273974}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 255 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.2753332}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.704615384615384e-06, '_timestamp': 1712283574.2758691}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 276. Dropping entry: {'time/batch': 256, 'time/sample': 65536, 'time/batch_in_epoch': 61, 'time/sample_in_epoch': 15616, '_timestamp': 1712283574.276712}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.346972}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0029524918645620346, '_timestamp': 1712283574.3471587}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 256 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.3484066}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.647692307692309e-06, '_timestamp': 1712283574.3489127}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 276. Dropping entry: {'time/batch': 257, 'time/sample': 65792, 'time/batch_in_epoch': 62, 'time/sample_in_epoch': 15872, '_timestamp': 1712283574.3495708}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.376313}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002825796604156494, '_timestamp': 1712283574.3765028}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 257 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.4324708}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.59076923076923e-06, '_timestamp': 1712283574.432991}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 276. Dropping entry: {'time/batch': 258, 'time/sample': 66048, 'time/batch_in_epoch': 63, 'time/sample_in_epoch': 16128, '_timestamp': 1712283574.4338505}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.461959}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002316616475582123, '_timestamp': 1712283574.462151}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 258 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.4634573}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.5338461538461535e-06, '_timestamp': 1712283574.4639537}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 276. Dropping entry: {'time/batch': 259, 'time/sample': 66304, 'time/batch_in_epoch': 64, 'time/sample_in_epoch': 16384, '_timestamp': 1712283574.4645271}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.5358799}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 276. Dropping entry: {'loss/train/total': 0.003413558006286621, '_timestamp': 1712283574.5360765}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 259 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.537355}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.476923076923079e-06, '_timestamp': 1712283574.53819}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0022032475098967552, 'l2_norm/param/network.bn1.weight': 1.1005334854125977, 'l2_norm/update/network.bn1.weight': 0.0002074806543532759, 'l2_norm/grad/network.bn1.weight': 0.013877278193831444, 'l2_norm/moment/network.bn1.bias': 0.0013331276131793857, 'l2_norm/param/network.bn1.bias': 0.9321138858795166, 'l2_norm/update/network.bn1.bias': 0.0001714931713650003, 'l2_norm/grad/network.bn1.bias': 0.006465420592576265, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.001471387455239892, 'l2_norm/param/network.layer1.0.bn1.weight': 1.1385385990142822, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00021403144637588412, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.006692985072731972, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.0012049023061990738, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6823410987854004, 'l2_norm/update/network.layer1.0.bn1.bias': 0.0001266950712306425, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.006544969044625759, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.0015723310643807054, 'l2_norm/param/network.layer1.0.bn2.weight': 1.3883756399154663, 'l2_norm/update/network.layer1.0.bn2.weight': 0.00025915392325259745, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.008420844562351704, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0011254226556047797, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7129314541816711, 'l2_norm/update/network.layer1.0.bn2.bias': 0.0001335825800197199, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.007402891758829355, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.0020972047932446003, 'l2_norm/param/network.layer1.1.bn1.weight': 1.3966469764709473, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00026177545078098774, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.009138384833931923, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0017275814898312092, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6044626235961914, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00011242213076911867, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.007554682902991772, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0017026519635692239, 'l2_norm/param/network.layer1.1.bn2.weight': 1.3076092004776, 'l2_norm/update/network.layer1.1.bn2.weight': 0.00024508885690011084, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.008153684437274933, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.0011427992722019553, 'l2_norm/param/network.layer1.1.bn2.bias': 0.8937058448791504, 'l2_norm/update/network.layer1.1.bn2.bias': 0.00016885451623238623, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.005991951562464237, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.00221874937415123, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6175305843353271, 'l2_norm/update/network.layer2.0.bn1.weight': 0.00030308152781799436, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.01284097321331501, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.001622021896764636, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7454690933227539, 'l2_norm/update/network.layer2.0.bn1.bias': 0.0001400681649101898, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.00916700717061758, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.0025905556976795197, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9125334024429321, 'l2_norm/update/network.layer2.0.bn2.weight': 0.00035795383155345917, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.013449250720441341, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.0016072045546025038, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6597336530685425, 'l2_norm/update/network.layer2.0.bn2.bias': 0.0001231645146617666, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.008471598848700523, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.002377590397372842, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.3991857767105103, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.0002617456193547696, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.012552224099636078, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.0016072045546025038, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6597336530685425, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.0001231645146617666, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.008471598848700523, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.0035618129186332226, 'l2_norm/param/network.layer2.1.bn1.weight': 1.5877408981323242, 'l2_norm/update/network.layer2.1.bn1.weight': 0.00029802144854329526, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.019064530730247498, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.002062913030385971, 'l2_norm/param/network.layer2.1.bn1.bias': 1.3871327638626099, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00025909877149388194, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.010649099014699459, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0022699180990457535, 'l2_norm/param/network.layer2.1.bn2.weight': 1.459631085395813, 'l2_norm/update/network.layer2.1.bn2.weight': 0.0002745109668467194, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.013301149941980839, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.0014435010962188244, 'l2_norm/param/network.layer2.1.bn2.bias': 0.906176745891571, 'l2_norm/update/network.layer2.1.bn2.bias': 0.00016908420366235077, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.0077865892089903355, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.0035061431117355824, 'l2_norm/param/network.layer3.0.bn1.weight': 2.224963426589966, 'l2_norm/update/network.layer3.0.bn1.weight': 0.0004164896090514958, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.02150229550898075, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.002138470532372594, 'l2_norm/param/network.layer3.0.bn1.bias': 1.3094254732131958, 'l2_norm/update/network.layer3.0.bn1.bias': 0.0002456093789078295, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.013126511126756668, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.005434808321297169, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5124027729034424, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0004691063950303942, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.029193740338087082, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.002815564163029194, 'l2_norm/param/network.layer3.0.bn2.bias': 1.382140874862671, 'l2_norm/update/network.layer3.0.bn2.bias': 0.0002599139988888055, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.015283172950148582, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.003274614689871669, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9171309471130371, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00017047372239176184, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.0192857813090086, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.002815564163029194, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.382140874862671, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.0002599139988888055, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.015283172950148582, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.005903804209083319, 'l2_norm/param/network.layer3.1.bn1.weight': 2.1475846767425537, 'l2_norm/update/network.layer3.1.bn1.weight': 0.0004016765160486102, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.030303955078125, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.003229271387681365, 'l2_norm/param/network.layer3.1.bn1.bias': 2.0502192974090576, 'l2_norm/update/network.layer3.1.bn1.bias': 0.00038479510112665594, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.015880832448601723, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0027779561933130026, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9565541744232178, 'l2_norm/update/network.layer3.1.bn2.weight': 0.0003691641613841057, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.016795611009001732, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.0016215573996305466, 'l2_norm/param/network.layer3.1.bn2.bias': 1.615602731704712, 'l2_norm/update/network.layer3.1.bn2.bias': 0.0003049499064218253, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.009736484847962856, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.0026728238444775343, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4332709312438965, 'l2_norm/update/network.layer4.0.bn1.weight': 0.00027307801065035164, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.017859887331724167, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.0019519306952133775, 'l2_norm/param/network.layer4.0.bn1.bias': 0.9884762167930603, 'l2_norm/update/network.layer4.0.bn1.bias': 0.0001838166208472103, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.014705453999340534, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0016546190017834306, 'l2_norm/param/network.layer4.0.bn2.weight': 3.912766218185425, 'l2_norm/update/network.layer4.0.bn2.weight': 0.0008544112206436694, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.002200168091803789, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0007912369328550994, 'l2_norm/param/network.layer4.0.bn2.bias': 0.6467872858047485, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00016032022540457547, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0031757240649312735, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0006156058516353369, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.90372896194458, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.00041425583185628057, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.001729171141050756, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0007912369328550994, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.6467872858047485, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00016032022540457547, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0031757240649312735, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.0011674099368974566, 'l2_norm/param/network.layer4.1.bn1.weight': 0.8908783197402954, 'l2_norm/update/network.layer4.1.bn1.weight': 0.0001892142026918009, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.004437309689819813, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0017265096539631486, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17131365835666656, 'l2_norm/update/network.layer4.1.bn1.bias': 5.1504997827578336e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.007333304267376661, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.002727043814957142, 'l2_norm/param/network.layer4.1.bn2.weight': 3.114166498184204, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0007300817524082959, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.003301700111478567, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0010347964707762003, 'l2_norm/param/network.layer4.1.bn2.bias': 0.883502721786499, 'l2_norm/update/network.layer4.1.bn2.bias': 0.00023228046484291553, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.002557076746597886, 'l2_norm/moment/network.fc.weight': 0.0034397426061332226, 'l2_norm/param/network.fc.weight': 5.6686248779296875, 'l2_norm/update/network.fc.weight': 0.0012781975092366338, 'l2_norm/grad/network.fc.weight': 0.008035603910684586, 'l2_norm/moment/network.fc.bias': 0.0002563590824138373, 'l2_norm/param/network.fc.bias': 0.09763660281896591, 'l2_norm/update/network.fc.bias': 1.7613714589970186e-05, 'l2_norm/grad/network.fc.bias': 0.0013685557059943676, 'l2_norm/grad/global': 0.08203675597906113, '_timestamp': 1712283574.5474358}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'time/batch': 260, 'time/sample': 66560, 'time/batch_in_epoch': 65, 'time/sample_in_epoch': 16640, '_timestamp': 1712283574.5492377}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.5769658}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0031740525737404823, '_timestamp': 1712283574.5771973}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 260 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.5785208}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.420000000000001e-06, '_timestamp': 1712283574.5790477}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 276. Dropping entry: {'time/batch': 261, 'time/sample': 66816, 'time/batch_in_epoch': 66, 'time/sample_in_epoch': 16896, '_timestamp': 1712283574.5797155}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.6551101}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0035804123617708683, '_timestamp': 1712283574.6553075}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 261 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.6566334}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.363076923076924e-06, '_timestamp': 1712283574.657138}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 276. Dropping entry: {'time/batch': 262, 'time/sample': 67072, 'time/batch_in_epoch': 67, 'time/sample_in_epoch': 17152, '_timestamp': 1712283574.6582026}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.7355473}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 276. Dropping entry: {'loss/train/total': 0.005287031177431345, '_timestamp': 1712283574.7357435}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 262 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.737054}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.306153846153845e-06, '_timestamp': 1712283574.7375472}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 276. Dropping entry: {'time/batch': 263, 'time/sample': 67328, 'time/batch_in_epoch': 68, 'time/sample_in_epoch': 17408, '_timestamp': 1712283574.7381299}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.7656205}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 276. Dropping entry: {'loss/train/total': 0.00513492152094841, '_timestamp': 1712283574.7658188}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 263 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.7672582}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.249230769230771e-06, '_timestamp': 1712283574.7677805}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 276. Dropping entry: {'time/batch': 264, 'time/sample': 67584, 'time/batch_in_epoch': 69, 'time/sample_in_epoch': 17664, '_timestamp': 1712283574.7686818}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.8483613}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002729421481490135, '_timestamp': 1712283574.848561}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 264 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.850102}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.192307692307692e-06, '_timestamp': 1712283574.8507724}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 276. Dropping entry: {'time/batch': 265, 'time/sample': 67840, 'time/batch_in_epoch': 70, 'time/sample_in_epoch': 17920, '_timestamp': 1712283574.8515415}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.878071}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002468954771757126, '_timestamp': 1712283574.8782613}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 265 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.8795328}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.135384615384615e-06, '_timestamp': 1712283574.8800054}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 276. Dropping entry: {'time/batch': 266, 'time/sample': 68096, 'time/batch_in_epoch': 71, 'time/sample_in_epoch': 18176, '_timestamp': 1712283574.8808444}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283574.955025}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 276. Dropping entry: {'loss/train/total': 0.00610921299085021, '_timestamp': 1712283574.9552224}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 266 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283574.9570885}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.078461538461541e-06, '_timestamp': 1712283574.9577656}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 276. Dropping entry: {'time/batch': 267, 'time/sample': 68352, 'time/batch_in_epoch': 72, 'time/sample_in_epoch': 18432, '_timestamp': 1712283574.958515}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.0358279}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 276. Dropping entry: {'loss/train/total': 0.005991912446916103, '_timestamp': 1712283575.0360286}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 267 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 0.99609375, '_timestamp': 1712283575.0374863}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 7.0215384615384615e-06, '_timestamp': 1712283575.038194}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 276. Dropping entry: {'time/batch': 268, 'time/sample': 68608, 'time/batch_in_epoch': 73, 'time/sample_in_epoch': 18688, '_timestamp': 1712283575.0392523}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.066636}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0031267390586435795, '_timestamp': 1712283575.0668373}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 268 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.0682647}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.964615384615386e-06, '_timestamp': 1712283575.0687823}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 276. Dropping entry: {'time/batch': 269, 'time/sample': 68864, 'time/batch_in_epoch': 74, 'time/sample_in_epoch': 18944, '_timestamp': 1712283575.0695746}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.1487553}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 276. Dropping entry: {'loss/train/total': 0.002166097518056631, '_timestamp': 1712283575.1489608}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 269 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.150289}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.907692307692306e-06, '_timestamp': 1712283575.1507792}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'l2_norm/moment/network.bn1.weight': 0.0022941415663808584, 'l2_norm/param/network.bn1.weight': 1.0985462665557861, 'l2_norm/update/network.bn1.weight': 0.00018830398039426655, 'l2_norm/grad/network.bn1.weight': 0.0027660427149385214, 'l2_norm/moment/network.bn1.bias': 0.0015707521233707666, 'l2_norm/param/network.bn1.bias': 0.9304258823394775, 'l2_norm/update/network.bn1.bias': 0.00016187359869945794, 'l2_norm/grad/network.bn1.bias': 0.002099529607221484, 'l2_norm/moment/network.layer1.0.bn1.weight': 0.0016954633174464107, 'l2_norm/param/network.layer1.0.bn1.weight': 1.1364898681640625, 'l2_norm/update/network.layer1.0.bn1.weight': 0.00019592756871134043, 'l2_norm/grad/network.layer1.0.bn1.weight': 0.002533348510041833, 'l2_norm/moment/network.layer1.0.bn1.bias': 0.001414001453667879, 'l2_norm/param/network.layer1.0.bn1.bias': 0.6811022162437439, 'l2_norm/update/network.layer1.0.bn1.bias': 0.00011900139361387119, 'l2_norm/grad/network.layer1.0.bn1.bias': 0.0017107264138758183, 'l2_norm/moment/network.layer1.0.bn2.weight': 0.0018858042312785983, 'l2_norm/param/network.layer1.0.bn2.weight': 1.3858617544174194, 'l2_norm/update/network.layer1.0.bn2.weight': 0.00023810347192920744, 'l2_norm/grad/network.layer1.0.bn2.weight': 0.0024334334302693605, 'l2_norm/moment/network.layer1.0.bn2.bias': 0.0014272340340539813, 'l2_norm/param/network.layer1.0.bn2.bias': 0.7116447687149048, 'l2_norm/update/network.layer1.0.bn2.bias': 0.00012474897084757686, 'l2_norm/grad/network.layer1.0.bn2.bias': 0.0019420968601480126, 'l2_norm/moment/network.layer1.1.bn1.weight': 0.0027035833336412907, 'l2_norm/param/network.layer1.1.bn1.weight': 1.394124984741211, 'l2_norm/update/network.layer1.1.bn1.weight': 0.00024041309370659292, 'l2_norm/grad/network.layer1.1.bn1.weight': 0.0023509026505053043, 'l2_norm/moment/network.layer1.1.bn1.bias': 0.0019370726076886058, 'l2_norm/param/network.layer1.1.bn1.bias': 0.6033772230148315, 'l2_norm/update/network.layer1.1.bn1.bias': 0.00010736843978520483, 'l2_norm/grad/network.layer1.1.bn1.bias': 0.0021847074385732412, 'l2_norm/moment/network.layer1.1.bn2.weight': 0.0025509484112262726, 'l2_norm/param/network.layer1.1.bn2.weight': 1.3052572011947632, 'l2_norm/update/network.layer1.1.bn2.weight': 0.00022671790793538094, 'l2_norm/grad/network.layer1.1.bn2.weight': 0.001990744611248374, 'l2_norm/moment/network.layer1.1.bn2.bias': 0.0015176449669525027, 'l2_norm/param/network.layer1.1.bn2.bias': 0.8921048045158386, 'l2_norm/update/network.layer1.1.bn2.bias': 0.0001550708111608401, 'l2_norm/grad/network.layer1.1.bn2.bias': 0.001248881802894175, 'l2_norm/moment/network.layer2.0.bn1.weight': 0.0030099155846983194, 'l2_norm/param/network.layer2.0.bn1.weight': 1.6146098375320435, 'l2_norm/update/network.layer2.0.bn1.weight': 0.0002790313446894288, 'l2_norm/grad/network.layer2.0.bn1.weight': 0.003220570972189307, 'l2_norm/moment/network.layer2.0.bn1.bias': 0.0017962666461244226, 'l2_norm/param/network.layer2.0.bn1.bias': 0.7441332340240479, 'l2_norm/update/network.layer2.0.bn1.bias': 0.00012923564645461738, 'l2_norm/grad/network.layer2.0.bn1.bias': 0.0022561962250620127, 'l2_norm/moment/network.layer2.0.bn2.weight': 0.003647655714303255, 'l2_norm/param/network.layer2.0.bn2.weight': 1.9090778827667236, 'l2_norm/update/network.layer2.0.bn2.weight': 0.00032839825144037604, 'l2_norm/grad/network.layer2.0.bn2.weight': 0.0045128739438951015, 'l2_norm/moment/network.layer2.0.bn2.bias': 0.0022751009091734886, 'l2_norm/param/network.layer2.0.bn2.bias': 0.6585441827774048, 'l2_norm/update/network.layer2.0.bn2.bias': 0.00011680704483296722, 'l2_norm/grad/network.layer2.0.bn2.bias': 0.002664807252585888, 'l2_norm/moment/network.layer2.0.downsample.1.weight': 0.003347137477248907, 'l2_norm/param/network.layer2.0.downsample.1.weight': 1.3966561555862427, 'l2_norm/update/network.layer2.0.downsample.1.weight': 0.00024090039369184524, 'l2_norm/grad/network.layer2.0.downsample.1.weight': 0.004345369059592485, 'l2_norm/moment/network.layer2.0.downsample.1.bias': 0.0022751009091734886, 'l2_norm/param/network.layer2.0.downsample.1.bias': 0.6585441827774048, 'l2_norm/update/network.layer2.0.downsample.1.bias': 0.00011680704483296722, 'l2_norm/grad/network.layer2.0.downsample.1.bias': 0.002664807252585888, 'l2_norm/moment/network.layer2.1.bn1.weight': 0.0047973631881177425, 'l2_norm/param/network.layer2.1.bn1.weight': 1.584879755973816, 'l2_norm/update/network.layer2.1.bn1.weight': 0.0002743910881690681, 'l2_norm/grad/network.layer2.1.bn1.weight': 0.0042623188346624374, 'l2_norm/moment/network.layer2.1.bn1.bias': 0.002733372850343585, 'l2_norm/param/network.layer2.1.bn1.bias': 1.384633183479309, 'l2_norm/update/network.layer2.1.bn1.bias': 0.00024039740674197674, 'l2_norm/grad/network.layer2.1.bn1.bias': 0.002451137639582157, 'l2_norm/moment/network.layer2.1.bn2.weight': 0.0028269977774471045, 'l2_norm/param/network.layer2.1.bn2.weight': 1.4570014476776123, 'l2_norm/update/network.layer2.1.bn2.weight': 0.0002533055958338082, 'l2_norm/grad/network.layer2.1.bn2.weight': 0.0032551626209169626, 'l2_norm/moment/network.layer2.1.bn2.bias': 0.002184704877436161, 'l2_norm/param/network.layer2.1.bn2.bias': 0.9045524001121521, 'l2_norm/update/network.layer2.1.bn2.bias': 0.0001594893547007814, 'l2_norm/grad/network.layer2.1.bn2.bias': 0.002070691669359803, 'l2_norm/moment/network.layer3.0.bn1.weight': 0.0057382057420909405, 'l2_norm/param/network.layer3.0.bn1.weight': 2.2209417819976807, 'l2_norm/update/network.layer3.0.bn1.weight': 0.0003832338552456349, 'l2_norm/grad/network.layer3.0.bn1.weight': 0.00643080472946167, 'l2_norm/moment/network.layer3.0.bn1.bias': 0.0032543030101805925, 'l2_norm/param/network.layer3.0.bn1.bias': 1.307092547416687, 'l2_norm/update/network.layer3.0.bn1.bias': 0.00023196925758384168, 'l2_norm/grad/network.layer3.0.bn1.bias': 0.0037672044709324837, 'l2_norm/moment/network.layer3.0.bn2.weight': 0.007884912192821503, 'l2_norm/param/network.layer3.0.bn2.weight': 2.5078580379486084, 'l2_norm/update/network.layer3.0.bn2.weight': 0.0004327633942011744, 'l2_norm/grad/network.layer3.0.bn2.weight': 0.008388478308916092, 'l2_norm/moment/network.layer3.0.bn2.bias': 0.004281474743038416, 'l2_norm/param/network.layer3.0.bn2.bias': 1.379661202430725, 'l2_norm/update/network.layer3.0.bn2.bias': 0.00024218788894359022, 'l2_norm/grad/network.layer3.0.bn2.bias': 0.0043901060707867146, 'l2_norm/moment/network.layer3.0.downsample.1.weight': 0.005736837163567543, 'l2_norm/param/network.layer3.0.downsample.1.weight': 0.9154312610626221, 'l2_norm/update/network.layer3.0.downsample.1.weight': 0.00015528687799815089, 'l2_norm/grad/network.layer3.0.downsample.1.weight': 0.005938399583101273, 'l2_norm/moment/network.layer3.0.downsample.1.bias': 0.004281474743038416, 'l2_norm/param/network.layer3.0.downsample.1.bias': 1.379661202430725, 'l2_norm/update/network.layer3.0.downsample.1.bias': 0.00024218788894359022, 'l2_norm/grad/network.layer3.0.downsample.1.bias': 0.0043901060707867146, 'l2_norm/moment/network.layer3.1.bn1.weight': 0.008871925063431263, 'l2_norm/param/network.layer3.1.bn1.weight': 2.1437063217163086, 'l2_norm/update/network.layer3.1.bn1.weight': 0.00037089025136083364, 'l2_norm/grad/network.layer3.1.bn1.weight': 0.008761443197727203, 'l2_norm/moment/network.layer3.1.bn1.bias': 0.00480002723634243, 'l2_norm/param/network.layer3.1.bn1.bias': 2.046529531478882, 'l2_norm/update/network.layer3.1.bn1.bias': 0.00035588262835517526, 'l2_norm/grad/network.layer3.1.bn1.bias': 0.005130311008542776, 'l2_norm/moment/network.layer3.1.bn2.weight': 0.0039283218793570995, 'l2_norm/param/network.layer3.1.bn2.weight': 1.9530667066574097, 'l2_norm/update/network.layer3.1.bn2.weight': 0.0003435515100136399, 'l2_norm/grad/network.layer3.1.bn2.weight': 0.004695054609328508, 'l2_norm/moment/network.layer3.1.bn2.bias': 0.002555440180003643, 'l2_norm/param/network.layer3.1.bn2.bias': 1.6127032041549683, 'l2_norm/update/network.layer3.1.bn2.bias': 0.0002806063275784254, 'l2_norm/grad/network.layer3.1.bn2.bias': 0.0030993614345788956, 'l2_norm/moment/network.layer4.0.bn1.weight': 0.004141033627092838, 'l2_norm/param/network.layer4.0.bn1.weight': 1.4307034015655518, 'l2_norm/update/network.layer4.0.bn1.weight': 0.00025403674226254225, 'l2_norm/grad/network.layer4.0.bn1.weight': 0.004895287100225687, 'l2_norm/moment/network.layer4.0.bn1.bias': 0.003169445088133216, 'l2_norm/param/network.layer4.0.bn1.bias': 0.986674964427948, 'l2_norm/update/network.layer4.0.bn1.bias': 0.00017414128524251282, 'l2_norm/grad/network.layer4.0.bn1.bias': 0.0038523036055266857, 'l2_norm/moment/network.layer4.0.bn2.weight': 0.0017551706405356526, 'l2_norm/param/network.layer4.0.bn2.weight': 3.9068856239318848, 'l2_norm/update/network.layer4.0.bn2.weight': 0.000786399410571903, 'l2_norm/grad/network.layer4.0.bn2.weight': 0.0015606579836457968, 'l2_norm/moment/network.layer4.0.bn2.bias': 0.0009953505359590054, 'l2_norm/param/network.layer4.0.bn2.bias': 0.645919144153595, 'l2_norm/update/network.layer4.0.bn2.bias': 0.00014649397053290159, 'l2_norm/grad/network.layer4.0.bn2.bias': 0.0009691086015664041, 'l2_norm/moment/network.layer4.0.downsample.1.weight': 0.0007366352365352213, 'l2_norm/param/network.layer4.0.downsample.1.weight': 1.9008251428604126, 'l2_norm/update/network.layer4.0.downsample.1.weight': 0.00038393554859794676, 'l2_norm/grad/network.layer4.0.downsample.1.weight': 0.0008013013866730034, 'l2_norm/moment/network.layer4.0.downsample.1.bias': 0.0009953505359590054, 'l2_norm/param/network.layer4.0.downsample.1.bias': 0.645919144153595, 'l2_norm/update/network.layer4.0.downsample.1.bias': 0.00014649397053290159, 'l2_norm/grad/network.layer4.0.downsample.1.bias': 0.0009691086015664041, 'l2_norm/moment/network.layer4.1.bn1.weight': 0.0016150771407410502, 'l2_norm/param/network.layer4.1.bn1.weight': 0.8894428014755249, 'l2_norm/update/network.layer4.1.bn1.weight': 0.00017582437430974096, 'l2_norm/grad/network.layer4.1.bn1.weight': 0.0019013140117749572, 'l2_norm/moment/network.layer4.1.bn1.bias': 0.0025514818262308836, 'l2_norm/param/network.layer4.1.bn1.bias': 0.17103330790996552, 'l2_norm/update/network.layer4.1.bn1.bias': 6.468856008723378e-05, 'l2_norm/grad/network.layer4.1.bn1.bias': 0.0022938402835279703, 'l2_norm/moment/network.layer4.1.bn2.weight': 0.002864524954929948, 'l2_norm/param/network.layer4.1.bn2.weight': 3.109969139099121, 'l2_norm/update/network.layer4.1.bn2.weight': 0.0006744227139279246, 'l2_norm/grad/network.layer4.1.bn2.weight': 0.0022930630948394537, 'l2_norm/moment/network.layer4.1.bn2.bias': 0.0011828078422695398, 'l2_norm/param/network.layer4.1.bn2.bias': 0.8825145363807678, 'l2_norm/update/network.layer4.1.bn2.bias': 0.0002149689826183021, 'l2_norm/grad/network.layer4.1.bn2.bias': 0.0011929166503250599, 'l2_norm/moment/network.fc.weight': 0.003801580285653472, 'l2_norm/param/network.fc.weight': 5.660431385040283, 'l2_norm/update/network.fc.weight': 0.0011879741214215755, 'l2_norm/grad/network.fc.weight': 0.004011927172541618, 'l2_norm/moment/network.fc.bias': 0.0003086765937041491, 'l2_norm/param/network.fc.bias': 0.09745708853006363, 'l2_norm/update/network.fc.bias': 1.8560955140856095e-05, 'l2_norm/grad/network.fc.bias': 0.0005299202748574317, 'l2_norm/grad/global': 0.023770632222294807, '_timestamp': 1712283575.1588576}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'time/batch': 270, 'time/sample': 69120, 'time/batch_in_epoch': 75, 'time/sample_in_epoch': 19200, '_timestamp': 1712283575.1606455}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.2356966}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0034084534272551537, '_timestamp': 1712283575.235897}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 270 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.2372065}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.850769230769232e-06, '_timestamp': 1712283575.2376993}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 276. Dropping entry: {'time/batch': 271, 'time/sample': 69376, 'time/batch_in_epoch': 76, 'time/sample_in_epoch': 19456, '_timestamp': 1712283575.2382855}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.2656713}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0020109903998672962, '_timestamp': 1712283575.2658563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 271 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.2671354}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.7938461538461555e-06, '_timestamp': 1712283575.2676146}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 276. Dropping entry: {'time/batch': 272, 'time/sample': 69632, 'time/batch_in_epoch': 77, 'time/sample_in_epoch': 19712, '_timestamp': 1712283575.2684429}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.3349113}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0056121391244232655, '_timestamp': 1712283575.3351018}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 272 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.3363547}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.736923076923076e-06, '_timestamp': 1712283575.3368366}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 276. Dropping entry: {'time/batch': 273, 'time/sample': 69888, 'time/batch_in_epoch': 78, 'time/sample_in_epoch': 19968, '_timestamp': 1712283575.3374827}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.3636422}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 276. Dropping entry: {'loss/train/total': 0.00377954775467515, '_timestamp': 1712283575.3638563}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 273 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.3651476}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.680000000000002e-06, '_timestamp': 1712283575.365633}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 276. Dropping entry: {'time/batch': 274, 'time/sample': 70144, 'time/batch_in_epoch': 79, 'time/sample_in_epoch': 20224, '_timestamp': 1712283575.3662436}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.4485893}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 276. Dropping entry: {'loss/train/total': 0.0048889946192502975, '_timestamp': 1712283575.4487941}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 274 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 1.0, '_timestamp': 1712283575.4502082}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 276. Dropping entry: {'lr-DecoupledAdamW/group0': 6.623076923076923e-06, '_timestamp': 1712283575.4507473}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 276. Dropping entry: {'time/batch': 275, 'time/sample': 70400, 'time/batch_in_epoch': 80, 'time/sample_in_epoch': 20480, '_timestamp': 1712283575.451659}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 276. Dropping entry: {'trainer/device_train_microbatch_size': 256, '_timestamp': 1712283575.4782858}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 276. Dropping entry: {'loss/train/total': 0.011647583916783333, '_timestamp': 1712283575.4786541}).
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 275 is less than current step: 276. Dropping entry: {'metrics/train/MulticlassAccuracy': 0.99609375, '_timestamp': 1712283575.5326073}).
train          Epoch   1:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [00:12<00:00, 20.87ba/s, loss/train/total=0.0048]
eval           Epoch   1:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 33.96ba/s, metrics/eval/MulticlassAccuracy=0.9490]